#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸è¶³ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import pickle
from pathlib import Path
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
import numpy as np

# ãƒ‘ã‚¹è¨­å®š
PROJECT_ROOT = Path(r"C:\work\ws_python\GenerationAiCamp")
ML_MODELS_PATH = PROJECT_ROOT / 'Lesson25' / 'uma3soft-app' / 'ml_models'

def create_missing_models():
    """ä¸è¶³ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    print("ğŸ”§ ä¸è¶³ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­...")

    # ãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ä½œæˆ
    print("  ğŸ“ ãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ä½œæˆä¸­...")
    vectorizer = TfidfVectorizer(
        max_features=310,
        ngram_range=(1, 2),
        stop_words='english'
    )

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã§fit
    sample_texts = [
        "ç¿”å¹³é¸æ‰‹ã®æˆç¸¾ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        "ãƒãƒ¼ãƒ ã®æˆ¦ç•¥ã‚’çŸ¥ã‚ŠãŸã„ã§ã™",
        "ç·´ç¿’ã¯ã„ã¤ã§ã™ã‹",
        "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™",
        "ãã®ä»–ã®è³ªå•ã§ã™",
        "é¸æ‰‹æƒ…å ±ã‚’ç¢ºèªã—ãŸã„",
        "è³ªå•ãŒã‚ã‚Šã¾ã™",
        "å›ç­”ã‚’ãŠé¡˜ã„ã—ã¾ã™",
        "ãƒãƒ¼ãƒ æƒ…å ±ã«ã¤ã„ã¦",
        "ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ"
    ]

    vectorizer.fit(sample_texts)

    # ä¿å­˜
    vectorizer_path = ML_MODELS_PATH / 'vectorizer.pkl'
    with open(vectorizer_path, 'wb') as f:
        pickle.dump(vectorizer, f)
    print(f"  âœ… ãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ä¿å­˜: {vectorizer_path}")

    # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä½œæˆ
    print("  ğŸ“Š ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä½œæˆä¸­...")
    scaler = StandardScaler()

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§fit
    sample_features = vectorizer.transform(sample_texts).toarray()
    scaler.fit(sample_features)

    # ä¿å­˜
    scaler_path = ML_MODELS_PATH / 'scaler.pkl'
    with open(scaler_path, 'wb') as f:
        pickle.dump(scaler, f)
    print(f"  âœ… ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä¿å­˜: {scaler_path}")

    print("ğŸ‰ ä¸è¶³ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†!")

if __name__ == "__main__":
    create_missing_models()

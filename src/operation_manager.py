#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Uma3 Software æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ é‹ç”¨ç®¡ç†ãƒ„ãƒ¼ãƒ«
æ—¥å¸¸é‹ç”¨ãƒ»ç›£è¦–ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãŸã‚ã®çµ±åˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
import json
import logging
import subprocess
import time
from datetime import datetime, timedelta
from pathlib import Path
import argparse
import psutil
import sqlite3

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè¨­å®š
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT))
sys.path.append(str(PROJECT_ROOT / 'src'))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(PROJECT_ROOT / 'logs' / 'operation_manager.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class Uma3OperationManager:
    """Uma3 æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ é‹ç”¨ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        # æ­£ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹è¨­å®š
        self.project_root = Path(r"C:\work\ws_python\GenerationAiCamp")
        self.venv_python = self.project_root / 'venv' / 'Scripts' / 'python.exe'
        self.ml_models_path = self.project_root / 'Lesson25' / 'uma3soft-app' / 'ml_models'
        self.logs_path = self.project_root / 'Lesson25' / 'uma3soft-app' / 'logs'
        self.src_path = self.project_root / 'Lesson25' / 'uma3soft-app' / 'src'

        # é‹ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.metrics = {
            'system_health': {},
            'performance': {},
            'errors': [],
            'maintenance_log': []
        }

    def check_system_health(self) -> dict:
        """ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ¥ ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­...")

        health_status = {
            'timestamp': datetime.now().isoformat(),
            'overall_status': 'healthy',
            'components': {}
        }

        try:
            # 1. Pythonç’°å¢ƒãƒã‚§ãƒƒã‚¯
            if self.venv_python.exists():
                health_status['components']['python_env'] = 'OK'
                print("  âœ… Pythonä»®æƒ³ç’°å¢ƒ: æ­£å¸¸")
            else:
                health_status['components']['python_env'] = 'ERROR'
                health_status['overall_status'] = 'unhealthy'
                print("  âŒ Pythonä»®æƒ³ç’°å¢ƒ: è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            # 2. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯
            required_models = [
                'classification_model.pkl',
                'clustering_model.pkl',
                'vectorizer.pkl',
                'scaler.pkl'
            ]

            missing_models = []
            for model in required_models:
                model_path = self.ml_models_path / model
                if model_path.exists():
                    size_mb = model_path.stat().st_size / 1024 / 1024
                    print(f"  âœ… {model}: æ­£å¸¸ ({size_mb:.1f}MB)")
                else:
                    missing_models.append(model)
                    print(f"  âŒ {model}: è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            if missing_models:
                health_status['components']['ml_models'] = f'MISSING: {missing_models}'
                health_status['overall_status'] = 'unhealthy'
            else:
                health_status['components']['ml_models'] = 'OK'

            # 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒã‚§ãƒƒã‚¯
            try:
                db_path = self.project_root / 'Lesson25' / 'uma3soft-app' / 'db' / 'chroma_store'
                if db_path.exists():
                    health_status['components']['database'] = 'OK'
                    print("  âœ… ChromaDB: æ¥ç¶šå¯èƒ½")
                else:
                    health_status['components']['database'] = 'WARNING'
                    print("  âš ï¸ ChromaDB: ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            except Exception as e:
                health_status['components']['database'] = f'ERROR: {e}'
                print(f"  âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {e}")

            # 4. ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯
            try:
                disk_usage = psutil.disk_usage(str(self.project_root))
                free_gb = disk_usage.free / 1024 / 1024 / 1024

                if free_gb > 5.0:  # 5GBä»¥ä¸Šã®ç©ºãå®¹é‡
                    health_status['components']['disk_space'] = f'OK ({free_gb:.1f}GB free)'
                    print(f"  âœ… ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡: {free_gb:.1f}GB åˆ©ç”¨å¯èƒ½")
                else:
                    health_status['components']['disk_space'] = f'WARNING ({free_gb:.1f}GB free)'
                    health_status['overall_status'] = 'warning'
                    print(f"  âš ï¸ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡: {free_gb:.1f}GBï¼ˆå®¹é‡ä¸è¶³ã®å¯èƒ½æ€§ï¼‰")

            except Exception as e:
                health_status['components']['disk_space'] = f'ERROR: {e}'
                print(f"  âŒ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯: {e}")

            # 5. ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
            python_processes = []
            ngrok_processes = []

            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    if proc.info['name'] and 'python' in proc.info['name'].lower():
                        if proc.info['cmdline'] and any('uma3' in cmd.lower() for cmd in proc.info['cmdline']):
                            python_processes.append(proc.info['pid'])

                    if proc.info['name'] and 'ngrok' in proc.info['name'].lower():
                        ngrok_processes.append(proc.info['pid'])

                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue

            health_status['components']['processes'] = {
                'python_processes': len(python_processes),
                'ngrok_processes': len(ngrok_processes)
            }

            print(f"  ğŸ“Š å®Ÿè¡Œä¸­ãƒ—ãƒ­ã‚»ã‚¹: Python={len(python_processes)}, ngrok={len(ngrok_processes)}")

        except Exception as e:
            logger.error(f"ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            health_status['overall_status'] = 'error'
            health_status['error'] = str(e)

        self.metrics['system_health'] = health_status
        return health_status

    def run_integration_test(self) -> dict:
        """çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print("ğŸ§ª æ©Ÿæ¢°å­¦ç¿’çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")

        test_result = {
            'timestamp': datetime.now().isoformat(),
            'success': False,
            'details': {}
        }

        try:
            # çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            test_script = self.src_path / 'ml_integration_test.py'

            if not test_script.exists():
                test_result['error'] = 'Integration test script not found'
                print("  âŒ çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return test_result

            cmd = [str(self.venv_python), str(test_script)]
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300,  # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                cwd=str(self.project_root)
            )

            if result.returncode == 0:
                test_result['success'] = True
                print("  âœ… çµ±åˆãƒ†ã‚¹ãƒˆæˆåŠŸ")

                # å‡ºåŠ›ã‹ã‚‰é‡è¦ãªæŒ‡æ¨™ã‚’æŠ½å‡º
                output_lines = result.stdout.split('\n')
                for line in output_lines:
                    if 'ğŸ¯ æˆåŠŸãƒ†ã‚¹ãƒˆ:' in line:
                        test_result['details']['success_rate'] = line.split(':')[1].strip()
                    elif 'âš¡ åˆ†é¡ç²¾åº¦:' in line:
                        test_result['details']['classification_accuracy'] = line.split(':')[1].strip()
                    elif 'ğŸ“Š å‡¦ç†ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ:' in line:
                        test_result['details']['throughput'] = line.split(':')[1].strip()

            else:
                test_result['success'] = False
                test_result['error'] = result.stderr
                print(f"  âŒ çµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•—: {result.stderr}")

            test_result['stdout'] = result.stdout
            test_result['stderr'] = result.stderr

        except subprocess.TimeoutExpired:
            test_result['error'] = 'Test execution timeout'
            print("  â° çµ±åˆãƒ†ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")

        except Exception as e:
            test_result['error'] = str(e)
            logger.error(f"çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            print(f"  âŒ çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

        return test_result

    def monitor_performance(self) -> dict:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–"""
        print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–å®Ÿè¡Œä¸­...")

        performance_data = {
            'timestamp': datetime.now().isoformat(),
            'cpu_usage': psutil.cpu_percent(interval=1),
            'memory_usage': psutil.virtual_memory().percent,
            'disk_io': psutil.disk_io_counters()._asdict() if psutil.disk_io_counters() else {},
            'network_io': psutil.net_io_counters()._asdict()
        }

        print(f"  ğŸ“ˆ CPUä½¿ç”¨ç‡: {performance_data['cpu_usage']:.1f}%")
        print(f"  ğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {performance_data['memory_usage']:.1f}%")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è­¦å‘Š
        warnings = []
        if performance_data['cpu_usage'] > 80:
            warnings.append("CPUä½¿ç”¨ç‡ãŒé«˜ã„")
        if performance_data['memory_usage'] > 85:
            warnings.append("ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„")

        if warnings:
            performance_data['warnings'] = warnings
            print("  âš ï¸ è­¦å‘Š: " + ", ".join(warnings))
        else:
            print("  âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ­£å¸¸")

        self.metrics['performance'] = performance_data
        return performance_data

    def retrain_models(self) -> dict:
        """ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´å®Ÿè¡Œ"""
        print("ğŸ”„ æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´å®Ÿè¡Œä¸­...")

        retrain_result = {
            'timestamp': datetime.now().isoformat(),
            'success': False,
            'details': {}
        }

        try:
            # ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
            train_script = self.src_path / 'ml_training_system_offline.py'

            if not train_script.exists():
                retrain_result['error'] = 'Training script not found'
                print("  âŒ è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return retrain_result

            cmd = [str(self.venv_python), str(train_script)]
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600,  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                cwd=str(self.project_root)
            )

            if result.returncode == 0:
                retrain_result['success'] = True
                print("  âœ… ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´æˆåŠŸ")

                # è¨“ç·´çµæœã‹ã‚‰ç²¾åº¦ã‚’æŠ½å‡º
                output_lines = result.stdout.split('\n')
                for line in output_lines:
                    if 'accuracy' in line.lower() or 'ç²¾åº¦' in line:
                        retrain_result['details']['accuracy'] = line.strip()
                        break

            else:
                retrain_result['success'] = False
                retrain_result['error'] = result.stderr
                print(f"  âŒ ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´å¤±æ•—: {result.stderr}")

            retrain_result['stdout'] = result.stdout
            retrain_result['stderr'] = result.stderr

        except subprocess.TimeoutExpired:
            retrain_result['error'] = 'Training timeout'
            print("  â° ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")

        except Exception as e:
            retrain_result['error'] = str(e)
            logger.error(f"ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"  âŒ ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ã‚¨ãƒ©ãƒ¼: {e}")

        return retrain_result

    def cleanup_logs(self, days_to_keep: int = 30) -> dict:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print(f"ğŸ§¹ {days_to_keep}æ—¥ä»¥å‰ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")

        cleanup_result = {
            'timestamp': datetime.now().isoformat(),
            'files_deleted': 0,
            'bytes_freed': 0,
            'errors': []
        }

        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)

            log_files = list(self.logs_path.glob('*.log*'))

            for log_file in log_files:
                try:
                    file_modified = datetime.fromtimestamp(log_file.stat().st_mtime)

                    if file_modified < cutoff_date:
                        file_size = log_file.stat().st_size
                        log_file.unlink()

                        cleanup_result['files_deleted'] += 1
                        cleanup_result['bytes_freed'] += file_size

                        print(f"  ğŸ—‘ï¸ å‰Šé™¤: {log_file.name} ({file_size} bytes)")

                except Exception as e:
                    cleanup_result['errors'].append(f"{log_file.name}: {e}")
                    print(f"  âŒ å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {log_file.name} - {e}")

            freed_mb = cleanup_result['bytes_freed'] / 1024 / 1024
            print(f"  âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {cleanup_result['files_deleted']}ãƒ•ã‚¡ã‚¤ãƒ«, {freed_mb:.1f}MBè§£æ”¾")

        except Exception as e:
            cleanup_result['errors'].append(str(e))
            logger.error(f"ãƒ­ã‚°ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"  âŒ ãƒ­ã‚°ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

        return cleanup_result

    def generate_status_report(self) -> dict:
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("ğŸ“‹ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")

        # å„ç¨®ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        health_status = self.check_system_health()
        integration_test = self.run_integration_test()
        performance_data = self.monitor_performance()

        # ç·åˆãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        report = {
            'report_timestamp': datetime.now().isoformat(),
            'system_health': health_status,
            'integration_test': integration_test,
            'performance': performance_data,
            'overall_status': self._determine_overall_status(health_status, integration_test, performance_data),
            'recommendations': self._generate_recommendations(health_status, integration_test, performance_data)
        }

        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        report_filename = f"system_status_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        report_path = self.logs_path / report_filename

        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"  ğŸ’¾ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")

        return report

    def _determine_overall_status(self, health, test, performance) -> str:
        """ç·åˆçŠ¶æ…‹åˆ¤å®š"""
        if health.get('overall_status') == 'error':
            return 'critical'
        elif not test.get('success', False):
            return 'degraded'
        elif health.get('overall_status') == 'unhealthy':
            return 'warning'
        elif performance.get('warnings'):
            return 'warning'
        else:
            return 'healthy'

    def _generate_recommendations(self, health, test, performance) -> list:
        """æ”¹å–„æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []

        # ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ã«åŸºã¥ãæ¨å¥¨
        if health.get('overall_status') == 'unhealthy':
            recommendations.append("ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å•é¡ŒãŒã‚ã‚Šã¾ã™ - è©³ç´°ç¢ºèªãŒå¿…è¦")

        # ãƒ†ã‚¹ãƒˆçµæœã«åŸºã¥ãæ¨å¥¨
        if not test.get('success', False):
            recommendations.append("çµ±åˆãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¦ã„ã¾ã™ - ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«åŸºã¥ãæ¨å¥¨
        if performance.get('warnings'):
            recommendations.append("ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã®ä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™ - æœ€é©åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")

        if not recommendations:
            recommendations.append("ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«ç¨¼åƒã—ã¦ã„ã¾ã™")

        return recommendations

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description='Uma3 Software ML System Operation Manager')
    parser.add_argument('--action', choices=[
        'health-check', 'test', 'monitor', 'retrain', 'cleanup', 'report', 'full-maintenance'
    ], default='report', help='å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³')
    parser.add_argument('--cleanup-days', type=int, default=30, help='ãƒ­ã‚°ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¿æŒæ—¥æ•°')

    args = parser.parse_args()

    manager = Uma3OperationManager()

    print("ğŸš€ Uma3 Software æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ é‹ç”¨ç®¡ç†ãƒ„ãƒ¼ãƒ«")
    print("=" * 60)

    try:
        if args.action == 'health-check':
            result = manager.check_system_health()
            print(f"\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {result['overall_status']}")

        elif args.action == 'test':
            result = manager.run_integration_test()
            print(f"\nğŸ§ª çµ±åˆãƒ†ã‚¹ãƒˆçµæœ: {'æˆåŠŸ' if result['success'] else 'å¤±æ•—'}")

        elif args.action == 'monitor':
            result = manager.monitor_performance()
            warnings = result.get('warnings', [])
            print(f"\nğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: {'è­¦å‘Šã‚ã‚Š' if warnings else 'æ­£å¸¸'}")

        elif args.action == 'retrain':
            result = manager.retrain_models()
            print(f"\nğŸ”„ ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´: {'æˆåŠŸ' if result['success'] else 'å¤±æ•—'}")

        elif args.action == 'cleanup':
            result = manager.cleanup_logs(args.cleanup_days)
            print(f"\nğŸ§¹ ãƒ­ã‚°ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {result['files_deleted']}ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤")

        elif args.action == 'report':
            result = manager.generate_status_report()
            print(f"\nğŸ“‹ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³: {result['overall_status']}")
            print("æ¨å¥¨äº‹é …:")
            for rec in result['recommendations']:
                print(f"  â€¢ {rec}")

        elif args.action == 'full-maintenance':
            print("\nğŸ”§ ãƒ•ãƒ«ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Ÿè¡Œä¸­...")

            # 1. ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
            health = manager.check_system_health()

            # 2. çµ±åˆãƒ†ã‚¹ãƒˆ
            test = manager.run_integration_test()

            # 3. ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ï¼ˆãƒ†ã‚¹ãƒˆå¤±æ•—æ™‚ï¼‰
            if not test.get('success', False):
                print("\nğŸ”„ ãƒ†ã‚¹ãƒˆå¤±æ•—ã®ãŸã‚ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ã‚’å®Ÿè¡Œ...")
                retrain = manager.retrain_models()

                if retrain['success']:
                    # å†è¨“ç·´å¾Œã«å†ãƒ†ã‚¹ãƒˆ
                    print("\nğŸ§ª å†è¨“ç·´å¾Œã®çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")
                    test = manager.run_integration_test()

            # 4. ãƒ­ã‚°ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            cleanup = manager.cleanup_logs(args.cleanup_days)

            # 5. æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = manager.generate_status_report()

            print(f"\nğŸ‰ ãƒ•ãƒ«ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Œäº† - ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³: {report['overall_status']}")

        print("\nâœ… é‹ç”¨ç®¡ç†ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå®Œäº†")
        return 0

    except Exception as e:
        logger.error(f"é‹ç”¨ç®¡ç†ãƒ„ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return 1

if __name__ == "__main__":
    exit(main())

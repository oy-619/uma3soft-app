#!/usr/bin/env python3
"""
ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ãƒãƒ¼ãƒ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä½œæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ãƒˆãƒ¼ã‚¯å±¥æ­´ã‹ã‚‰ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é–¢é€£ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã€
æ©Ÿæ¢°å­¦ç¿’ç”¨ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹
"""

import os
import re
import json
import sqlite3
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
import pandas as pd

@dataclass
class SoftballData:
    """ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é–¢é€£ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ """
    timestamp: str
    user: str
    category: str  # ç·´ç¿’ã€è©¦åˆã€æˆ¦è¡“ã€é¸æ‰‹æƒ…å ±ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç­‰
    content: str
    players_mentioned: List[str]
    keywords: List[str]
    metadata: Dict

class SoftballDataExtractor:
    """ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        # ç¢ºèªæ¸ˆã¿é¸æ‰‹ï¼ˆ28åï¼‰
        self.confirmed_players = [
            "é™¸åŠŸ", "æ¹Š", "éŒ¬", "å—", "çµ±å¸", "æ˜¥è¼", "æ–°", "ç”±çœ", "å¿ƒå¯§", "å”¯æµ¬",
            "æœ‹æ¨¹", "ä½‘å¤š", "ç©‚ç¾", "ç¿”å¹³", "å°šçœŸ", "æŸšå¸Œ", "å¿ƒç¿”", "åºƒèµ·", "æƒ³çœŸ",
            "å¥", "è‹±æ±°", "è¡å¤ª", "æš–å¤§", "æ‚ ç‰", "é™½", "ç¾ç–é‡Œ", "å„ª", "å‹˜å¤ª"
        ]

        # ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        self.softball_keywords = {
            "ç·´ç¿’": ["ç·´ç¿’", "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°", "ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°", "ã‚­ãƒ£ãƒƒãƒãƒœãƒ¼ãƒ«", "ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°",
                   "å®ˆå‚™", "ãƒ”ãƒƒãƒãƒ³ã‚°", "ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°", "åŸºç¤ç·´ç¿’", "å®Ÿæˆ¦ç·´ç¿’"],
            "è©¦åˆ": ["è©¦åˆ", "ã‚²ãƒ¼ãƒ ", "å¯¾æˆ¦", "ãƒªãƒ¼ã‚°æˆ¦", "ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆ", "å…¬å¼æˆ¦",
                   "ç·´ç¿’è©¦åˆ", "çœŒå¤§ä¼š", "åœ°åŒºå¤§ä¼š", "æ±ºå‹", "æº–æ±ºå‹"],
            "æˆ¦è¡“": ["æˆ¦è¡“", "ä½œæˆ¦", "ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³", "æ‰“é †", "å®ˆå‚™ä½ç½®", "ã‚·ãƒ•ãƒˆ",
                   "ãƒãƒ³ãƒˆ", "ç›—å¡", "é€ã‚Šãƒãƒ³ãƒˆ", "ã‚¹ã‚¯ã‚¤ã‚º", "ä»£æ‰“", "ä»£èµ°"],
            "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«": ["æ—¥ç¨‹", "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«", "äºˆå®š", "æ™‚é–“", "é›†åˆ", "è§£æ•£",
                          "é…åˆ»", "æ¬ å¸­", "å‚åŠ ", "ä¸å‚åŠ ", "æ™‚é–“å¤‰æ›´"],
            "æˆç¸¾": ["ã‚¹ã‚³ã‚¢", "å¾—ç‚¹", "å¤±ç‚¹", "å‹åˆ©", "æ•—åŒ—", "å¼•ãåˆ†ã‘", "æ‰“ç‡",
                   "é˜²å¾¡ç‡", "ã‚¨ãƒ©ãƒ¼", "ãƒ’ãƒƒãƒˆ", "ãƒ›ãƒ¼ãƒ ãƒ©ãƒ³", "ä¸‰æŒ¯"],
            "ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³": ["æ€ªæˆ‘", "ä½“èª¿", "ç–²åŠ´", "å›å¾©", "ãƒªãƒãƒ“ãƒª", "ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹",
                           "ã‚¹ãƒˆãƒ¬ãƒƒãƒ", "ã‚¢ã‚¤ã‚·ãƒ³ã‚°", "ãƒ†ãƒ¼ãƒ”ãƒ³ã‚°"],
            "é“å…·": ["ã‚°ãƒ­ãƒ¼ãƒ–", "ãƒãƒƒãƒˆ", "ãƒœãƒ¼ãƒ«", "ãƒ˜ãƒ«ãƒ¡ãƒƒãƒˆ", "ãƒ¦ãƒ‹ãƒ•ã‚©ãƒ¼ãƒ ",
                   "ã‚¹ãƒ‘ã‚¤ã‚¯", "é“å…·", "ç”¨å…·", "ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹"],
            "æ„Ÿè¬ãƒ»å¿œæ´": ["ã‚ã‚ŠãŒã¨ã†", "æ„Ÿè¬", "ãŠç–²ã‚Œæ§˜", "é ‘å¼µã£ã¦", "å¿œæ´",
                        "åŠ±ã¾ã—", "ã‚µãƒãƒ¼ãƒˆ", "ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯"]
        }

        # æ™‚é–“ãƒ»æ—¥ä»˜é–¢é€£ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.time_patterns = [
            r'\d{1,2}:\d{2}',  # 14:30
            r'\d{1,2}æ™‚\d{0,2}åˆ†?',  # 14æ™‚30åˆ†
            r'åˆå‰|åˆå¾Œ',
            r'\d{1,2}æœˆ\d{1,2}æ—¥',  # 10æœˆ22æ—¥
            r'ä»Šæ—¥|æ˜æ—¥|æ˜¨æ—¥|æ¥é€±|ä»Šé€±'
        ]

    def extract_players_from_text(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰é¸æ‰‹åã‚’æŠ½å‡º"""
        mentioned_players = []
        for player in self.confirmed_players:
            if player in text:
                mentioned_players.append(player)
        return mentioned_players

    def categorize_message(self, text: str) -> str:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®š"""
        text_lower = text.lower()

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ã‚¹ã‚³ã‚¢è¨ˆç®—
        category_scores = {}
        for category, keywords in self.softball_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            if score > 0:
                category_scores[category] = score

        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ã‚«ãƒ†ã‚´ãƒªã‚’è¿”ã™
        if category_scores:
            return max(category_scores.items(), key=lambda x: x[1])[0]

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚«ãƒ†ã‚´ãƒª
        return "ãã®ä»–"

    def extract_keywords(self, text: str, category: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        keywords = []

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æŠ½å‡º
        if category in self.softball_keywords:
            for keyword in self.softball_keywords[category]:
                if keyword in text:
                    keywords.append(keyword)

        # æ™‚é–“ãƒ»æ—¥ä»˜ã®æŠ½å‡º
        for pattern in self.time_patterns:
            matches = re.findall(pattern, text)
            keywords.extend(matches)

        return list(set(keywords))  # é‡è¤‡é™¤å»

    def extract_metadata(self, text: str, user: str, timestamp: str) -> Dict:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º"""
        metadata = {
            "message_length": len(text),
            "has_question": "ï¼Ÿ" in text or "?" in text,
            "has_exclamation": "ï¼" in text or "!" in text,
            "has_emoji": bool(re.search(r'[ğŸ˜€-ğŸ™]', text)),
            "word_count": len(text.split()),
            "is_weekend": self._is_weekend_from_timestamp(timestamp),
            "hour": self._extract_hour_from_timestamp(timestamp)
        }
        return metadata

    def _is_weekend_from_timestamp(self, timestamp: str) -> bool:
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‹ã‚‰é€±æœ«ã‹ã©ã†ã‹åˆ¤å®š"""
        try:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®è§£æã‚’è©¦è¡Œ
            if "(" in timestamp and ")" in timestamp:
                day_match = re.search(r'\(([æœˆç«æ°´æœ¨é‡‘åœŸæ—¥])\)', timestamp)
                if day_match:
                    day = day_match.group(1)
                    return day in ['åœŸ', 'æ—¥']
        except:
            pass
        return False

    def _extract_hour_from_timestamp(self, timestamp: str) -> Optional[int]:
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‹ã‚‰æ™‚é–“ã‚’æŠ½å‡º"""
        try:
            time_match = re.search(r'(\d{1,2}):\d{2}', timestamp)
            if time_match:
                return int(time_match.group(1))
        except:
            pass
        return None

def extract_softball_data_from_chromadb(persist_directory: str) -> List[SoftballData]:
    """ChromaDBã‹ã‚‰ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""

    extractor = SoftballDataExtractor()
    softball_data = []

    # ChromaDBã«æ¥ç¶š
    chroma_db_file = os.path.join(persist_directory, "chroma.sqlite3")

    if not os.path.exists(chroma_db_file):
        print(f"âŒ ChromaDBãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {chroma_db_file}")
        return []

    try:
        conn = sqlite3.connect(chroma_db_file)
        cursor = conn.cursor()

        # documentsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        # ChromaDBã®å®Ÿéš›ã®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«åˆã‚ã›ã¦èª¿æ•´
        cursor.execute("""
            SELECT DISTINCT c0 as document
            FROM embedding_fulltext_search_content
            ORDER BY rowid DESC
        """)

        documents = cursor.fetchall()
        print(f"ğŸ“Š å–å¾—ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(documents)}")

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚‚è©¦è¡Œ
        cursor.execute("""
            SELECT id, key, string_value
            FROM embedding_metadata
            WHERE key IN ('user', 'timestamp', 'message_type')
        """)

        metadata_records = cursor.fetchall()
        metadata_dict = {}

        for record in metadata_records:
            doc_id, key, value = record
            if doc_id not in metadata_dict:
                metadata_dict[doc_id] = {}
            metadata_dict[doc_id][key] = value

        print(f"ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(metadata_records)}")

        # å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†
        for i, (document,) in enumerate(documents):
            if not document or not document.strip():
                continue

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
            doc_metadata = metadata_dict.get(i, {})
            user = doc_metadata.get('user', 'unknown')
            timestamp = doc_metadata.get('timestamp', 'unknown')

            # ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é–¢é€£ã®åˆ¤å®š
            category = extractor.categorize_message(document)

            # ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é–¢é€£ã§ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if category == "ãã®ä»–":
                # é¸æ‰‹åãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                players = extractor.extract_players_from_text(document)
                if not players:
                    continue

            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            players = extractor.extract_players_from_text(document)
            keywords = extractor.extract_keywords(document, category)
            metadata = extractor.extract_metadata(document, user, timestamp)

            # SoftballDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
            softball_entry = SoftballData(
                timestamp=timestamp,
                user=user,
                category=category,
                content=document,
                players_mentioned=players,
                keywords=keywords,
                metadata=metadata
            )

            softball_data.append(softball_entry)

            # é€²æ—è¡¨ç¤º
            if (i + 1) % 100 == 0:
                print(f"ğŸ“ å‡¦ç†ä¸­: {i + 1}/{len(documents)} ({len(softball_data)}ä»¶ã®ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿æŠ½å‡º)")

        conn.close()

    except Exception as e:
        print(f"âŒ ChromaDBå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return []

    print(f"âœ… ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå®Œäº†: {len(softball_data)}ä»¶")
    return softball_data

def save_softball_data_to_files(softball_data: List[SoftballData], output_dir: str):
    """ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å„ç¨®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ä¿å­˜"""

    os.makedirs(output_dir, exist_ok=True)

    # 1. JSONå½¢å¼ã§ä¿å­˜
    json_file = os.path.join(output_dir, "softball_learning_data.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump([asdict(data) for data in softball_data], f,
                 ensure_ascii=False, indent=2)
    print(f"ğŸ“„ JSONä¿å­˜å®Œäº†: {json_file}")

    # 2. CSVå½¢å¼ã§ä¿å­˜
    csv_file = os.path.join(output_dir, "softball_learning_data.csv")
    df_data = []

    for data in softball_data:
        row = {
            'timestamp': data.timestamp,
            'user': data.user,
            'category': data.category,
            'content': data.content,
            'players_mentioned': ','.join(data.players_mentioned),
            'keywords': ','.join(data.keywords),
            'message_length': data.metadata.get('message_length', 0),
            'has_question': data.metadata.get('has_question', False),
            'has_exclamation': data.metadata.get('has_exclamation', False),
            'has_emoji': data.metadata.get('has_emoji', False),
            'is_weekend': data.metadata.get('is_weekend', False),
            'hour': data.metadata.get('hour', None)
        }
        df_data.append(row)

    df = pd.DataFrame(df_data)
    df.to_csv(csv_file, index=False, encoding='utf-8')
    print(f"ğŸ“Š CSVä¿å­˜å®Œäº†: {csv_file}")

    # 3. ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
    stats_file = os.path.join(output_dir, "softball_statistics.json")

    category_stats = {}
    player_stats = {}
    keyword_stats = {}

    for data in softball_data:
        # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ
        category_stats[data.category] = category_stats.get(data.category, 0) + 1

        # é¸æ‰‹çµ±è¨ˆ
        for player in data.players_mentioned:
            player_stats[player] = player_stats.get(player, 0) + 1

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ±è¨ˆ
        for keyword in data.keywords:
            keyword_stats[keyword] = keyword_stats.get(keyword, 0) + 1

    statistics = {
        "total_messages": len(softball_data),
        "category_distribution": dict(sorted(category_stats.items(), key=lambda x: x[1], reverse=True)),
        "top_mentioned_players": dict(sorted(player_stats.items(), key=lambda x: x[1], reverse=True)[:10]),
        "top_keywords": dict(sorted(keyword_stats.items(), key=lambda x: x[1], reverse=True)[:20]),
        "generated_at": datetime.now().isoformat()
    }

    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(statistics, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“ˆ çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {stats_file}")

    return statistics

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ¥ ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ãƒãƒ¼ãƒ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä½œæˆ")
    print("=" * 60)

    # è¨­å®š
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    persist_directory = os.path.join(project_root, "db", "chroma_store")
    output_dir = os.path.join(project_root, "softball_learning_data")

    print(f"ğŸ“ ChromaDB: {persist_directory}")
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")

    # ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
    print("\nğŸ” ChromaDBã‹ã‚‰ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­...")
    softball_data = extract_softball_data_from_chromadb(persist_directory)

    if not softball_data:
        print("âŒ ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é–¢é€£ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    print(f"\nğŸ’¾ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ä¸­...")
    statistics = save_softball_data_to_files(softball_data, output_dir)

    # çµæœè¡¨ç¤º
    print("\n" + "=" * 60)
    print("ğŸ“Š ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†!")
    print("=" * 60)
    print(f"âœ… ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {statistics['total_messages']}")
    print(f"âœ… ã‚«ãƒ†ã‚´ãƒªæ•°: {len(statistics['category_distribution'])}")
    print(f"âœ… è¨€åŠã•ã‚ŒãŸé¸æ‰‹æ•°: {len(statistics['top_mentioned_players'])}")

    print(f"\nğŸ“‹ ä¸»è¦ãªã‚«ãƒ†ã‚´ãƒª:")
    for category, count in list(statistics['category_distribution'].items())[:5]:
        print(f"   - {category}: {count}ä»¶")

    print(f"\nğŸ‘¥ ã‚ˆãè¨€åŠã•ã‚Œã‚‹é¸æ‰‹:")
    for player, count in list(statistics['top_mentioned_players'].items())[:5]:
        print(f"   - {player}: {count}å›")

    print(f"\nğŸ“ ä¿å­˜å…ˆ: {output_dir}")
    print(f"   - softball_learning_data.json (è©³ç´°ãƒ‡ãƒ¼ã‚¿)")
    print(f"   - softball_learning_data.csv (è¡¨å½¢å¼)")
    print(f"   - softball_statistics.json (çµ±è¨ˆæƒ…å ±)")

if __name__ == "__main__":
    main()

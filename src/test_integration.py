#!/usr/bin/env python3
"""
LangChain + LlamaIndex çµ±åˆã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
çµ±åˆã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ã®æ©Ÿèƒ½ã¨æ€§èƒ½ã‚’åŒ…æ‹¬çš„ã«ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import time
from datetime import datetime

def test_integrated_system():
    """çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("ğŸš€ LangChain + LlamaIndex çµ±åˆã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼")
    print("=" * 60)

    try:
        # ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
        print("\nğŸ“¦ ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ...")

        # 1. åŸºæœ¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from uma3_llama_index_engine import Uma3LlamaIndexEngine, test_llama_index_integration
        from uma3_hybrid_rag_engine import Uma3HybridRAGEngine, test_hybrid_rag_engine
        from uma3_custom_tools import create_enhanced_custom_tools
        print("   âœ… å…¨ã¦ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸ")

        # 2. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰RAGã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ†ã‚¹ãƒˆ
        print("\nğŸ”„ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰RAGã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ...")

        engine = Uma3HybridRAGEngine(
            chroma_persist_directory="test_integration_chroma",
            enable_langchain=True,
            enable_llama_index=True
        )

        # ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆæƒ…å ±ã®å–å¾—
        stats = engine.get_hybrid_stats()
        print(f"   ğŸ“Š ã‚¨ãƒ³ã‚¸ãƒ³çµ±è¨ˆ: {stats}")

        # 3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
        print("\nğŸ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ...")

        test_documents = [
            "ã“ã‚Œã¯LangChainã¨LlamaIndexã®çµ±åˆãƒ†ã‚¹ãƒˆã§ã™ã€‚",
            {"text": "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰RAGã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚", "metadata": {"type": "integration_test"}},
            "è¤‡æ•°ã®RAGã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½µç”¨ã™ã‚‹ã“ã¨ã§æ¤œç´¢ç²¾åº¦ãŒå¤§å¹…ã«å‘ä¸Šã—ã¾ã—ãŸã€‚",
            "LangChainã®Agentã‚·ã‚¹ãƒ†ãƒ ã¨LlamaIndexã®QueryEngineãŒé€£æºã—ã¦ã„ã¾ã™ã€‚",
            "ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ã‚’é€šã˜ã¦é«˜åº¦ãªè³ªå•å¿œç­”ãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚"
        ]

        add_results = engine.add_documents_to_both(test_documents)
        print(f"   âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ çµæœ: {add_results}")

        # 4. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®ãƒ†ã‚¹ãƒˆ
        print("\nğŸ” ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ãƒ†ã‚¹ãƒˆ...")

        search_queries = [
            "çµ±åˆãƒ†ã‚¹ãƒˆ",
            "RAGã‚·ã‚¹ãƒ†ãƒ ",
            "LangChain LlamaIndex"
        ]

        for query in search_queries:
            print(f"\n   æ¤œç´¢ã‚¯ã‚¨ãƒª: '{query}'")
            results = engine.hybrid_search(query, k=3)

            print(f"   çµæœæ•°: {len(results)}")
            for i, doc in enumerate(results, 1):
                score = doc.metadata.get('hybrid_score', 0)
                engine_name = doc.metadata.get('engine', 'unknown')
                content = doc.page_content[:60].replace('\n', ' ')
                print(f"     {i}. [{engine_name}] Score: {score:.3f} - {content}...")

        # 5. LlamaIndexã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ†ã‚¹ãƒˆ
        print("\nğŸ§  LlamaIndexã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ...")

        if engine.llama_index_engine:
            query_questions = [
                "çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´ã¯ä½•ã§ã™ã‹ï¼Ÿ",
                "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆ©ç‚¹ã«ã¤ã„ã¦æ•™ãˆã¦",
                "LangChainã¨LlamaIndexã®é•ã„ã¯ï¼Ÿ"
            ]

            for question in query_questions:
                print(f"\n   è³ªå•: '{question}'")
                response = engine.llama_index_query(question, top_k=3)
                if response:
                    print(f"   å›ç­”: {response[:120]}...")
                else:
                    print("   å›ç­”: å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

        # 6. ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ
        print("\nğŸ› ï¸ æ‹¡å¼µã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ...")

        # LangChainäº’æ›ã®RAGã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰
        from uma3_chroma_improver import Uma3ChromaDBImprover
        from langchain_chroma import Chroma
        from langchain_huggingface import HuggingFaceEmbeddings

        # ç°¡æ˜“RAGã‚¨ãƒ³ã‚¸ãƒ³
        embedding_model = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        vector_db = Chroma(
            persist_directory="test_integration_chroma",
            embedding_function=embedding_model,
        )
        mock_rag_engine = Uma3ChromaDBImprover(vector_db)

        # æ‹¡å¼µã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ
        custom_tools = create_enhanced_custom_tools(
            rag_engine=mock_rag_engine,
            hybrid_rag_engine=engine
        )

        print(f"   âœ… ä½œæˆã•ã‚ŒãŸã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«æ•°: {len(custom_tools)}")
        for tool in custom_tools:
            print(f"     - {tool.name}: {tool.description.strip().split('.')[0]}...")

        # 7. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
        print("\nâš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ...")

        # æ¤œç´¢é€Ÿåº¦ãƒ†ã‚¹ãƒˆ
        start_time = time.time()
        for _ in range(5):
            results = engine.hybrid_search("ãƒ†ã‚¹ãƒˆ", k=5)
        end_time = time.time()

        avg_time = (end_time - start_time) / 5
        print(f"   ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ å¹³å‡å®Ÿè¡Œæ™‚é–“: {avg_time:.3f}ç§’")

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¦‚ç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        try:
            import psutil
            process = psutil.Process()
            memory_usage = process.memory_info().rss / 1024 / 1024  # MB
            print(f"   ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_usage:.1f} MB")
        except ImportError:
            print("   ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: psutilæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆæ¸¬å®šã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            memory_usage = 0

        # 8. ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
        print("\nğŸ”’ ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯...")

        system_status = {
            "langchain_engine": engine.langchain_engine is not None,
            "llama_index_engine": engine.llama_index_engine is not None and engine.llama_index_engine.is_initialized,
            "hybrid_search": len(engine.hybrid_search("test", k=1)) > 0,
            "custom_tools": len(custom_tools) >= 4
        }

        all_ok = all(system_status.values())

        print(f"   ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:")
        for component, status in system_status.items():
            status_icon = "âœ…" if status else "âŒ"
            print(f"     {status_icon} {component}: {status}")

        # æœ€çµ‚çµæœ
        print("\n" + "=" * 60)
        if all_ok:
            print("ğŸ‰ LangChain + LlamaIndex çµ±åˆã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼å®Œäº†!")
            print("   å…¨ã¦ã®æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")

            # ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦
            print(f"\nğŸ“‹ ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦:")
            print(f"   - RAGã‚¨ãƒ³ã‚¸ãƒ³: LangChain + LlamaIndex ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰")
            print(f"   - ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«: {len(custom_tools)}å€‹")
            print(f"   - æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³: ä¸¡æ–¹ã®ã‚¨ãƒ³ã‚¸ãƒ³ãŒç¨¼åƒä¸­")
            print(f"   - å¹³å‡æ¤œç´¢æ™‚é–“: {avg_time:.3f}ç§’")
            if memory_usage > 0:
                print(f"   - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_usage:.1f} MB")
            else:
                print(f"   - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: æ¸¬å®šã‚¹ã‚­ãƒƒãƒ—")

            return True
        else:
            print("âš ï¸ ä¸€éƒ¨ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
            return False

    except Exception as e:
        print(f"\nâŒ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_integrated_system()
    sys.exit(0 if success else 1)

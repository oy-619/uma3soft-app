"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰è¿½åŠ é¸æ‰‹æƒ…å ±ã‚’æŠ½å‡ºãƒ»å­¦ç¿’ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import sqlite3
import re
import json
from datetime import datetime
from typing import List, Dict, Set, Optional
import os

class AdditionalPlayerExtractor:
    """è¿½åŠ é¸æ‰‹æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, db_path: str):
        self.db_path = db_path

        # æ—¢å­˜ã®13å
        self.existing_players = [
            "é™¸åŠŸ", "æ¹Š", "éŒ¬", "å—", "çµ±å¸", "æ˜¥è¼", "æ–°",
            "ç”±çœ", "å¿ƒå¯§", "å”¯æµ¬", "æœ‹æ¨¹", "ä½‘å¤š", "ç©‚ç¾"
        ]

        # æ–°ãŸã«ç™ºè¦‹ã•ã‚ŒãŸé¸æ‰‹
        self.new_players = set()

        # ã‚ˆã‚Šå³å¯†ãªäººåãƒ‘ã‚¿ãƒ¼ãƒ³
        self.name_patterns = [
            r'([ä¸€-é¾¯]{2,4})(?:é¸æ‰‹|å›|ã•ã‚“|ã¡ã‚ƒã‚“)',  # æ¼¢å­— + æ•¬ç§°
            r'([ä¸€-é¾¯]{2,4})(?:ãŒ|ã¯|ã‚‚|ã®|ã‚’|ã«|ã§|ã¨)\s*(?:å‚åŠ |å‡ºå ´|ç™»éŒ²|ãƒ¡ãƒ³ãƒãƒ¼)',  # å‚åŠ é–¢é€£
            r'([ä¸€-é¾¯]{2,4})(?:ãŒ|ã¯|ã‚‚|ã®|ã‚’|ã«|ã§|ã¨)\s*(?:æŠ•ã’|æ‰“ã£|èµ°ã£|å®ˆã£)',  # å‹•ä½œé–¢é€£
            r'([ä¸€-é¾¯]{2,4})(?:ãŒ|ã¯|ã‚‚|ã®|ã‚’|ã«|ã§|ã¨)\s*(?:å¾—ç‚¹|ãƒ’ãƒƒãƒˆ|ã‚¨ãƒ©ãƒ¼)',  # æˆç¸¾é–¢é€£
            r'([ä¸€-é¾¯]{2,4})(?:ç•ª|ä½|å¹´|çµ„)',  # ç•ªå·ãƒ»å­¦å¹´é–¢é€£
            r'(?:ã‚³ãƒ¼ãƒ|ç›£ç£|ã‚­ãƒ£ãƒ—ãƒ†ãƒ³)ã®([ä¸€-é¾¯]{2,4})',  # å½¹è·é–¢é€£
        ]

        # é™¤å¤–ã™ã‚‹ä¸€èˆ¬èªå½™ï¼ˆæ‹¡å¼µç‰ˆï¼‰
        self.excluded_words = {
            # åŸºæœ¬é™¤å¤–èª
            'å°å­¦ç”Ÿ', 'ä¸­å­¦ç”Ÿ', 'é«˜æ ¡ç”Ÿ', 'å¤§å­¦ç”Ÿ', 'ç¤¾ä¼šäºº', 'å­ä¾›', 'å¤§äºº',
            'é¸æ‰‹', 'ãƒãƒ¼ãƒ ', 'è©¦åˆ', 'ç·´ç¿’', 'å¤§ä¼š', 'ç›£ç£', 'ã‚³ãƒ¼ãƒ', 'ã‚­ãƒ£ãƒ—ãƒ†ãƒ³',
            'æŠ•æ‰‹', 'æ•æ‰‹', 'å†…é‡æ‰‹', 'å¤–é‡æ‰‹', 'ãƒ”ãƒƒãƒãƒ£ãƒ¼', 'ã‚­ãƒ£ãƒƒãƒãƒ£ãƒ¼',

            # æ™‚é–“ãƒ»æœŸé–“é–¢é€£
            'ä»Šæ—¥', 'æ˜æ—¥', 'æ˜¨æ—¥', 'ä»Šå¹´', 'æ¥å¹´', 'å»å¹´', 'æœ€è¿‘', 'ä»Šåº¦', 'ä»Šå›', 'å‰å›',
            'ä»Šæœˆ', 'å…ˆæœˆ', 'æ¥æœˆ', 'ä»Šé€±', 'å…ˆé€±', 'æ¥é€±', 'å½“æ—¥', 'ç¿Œæ—¥', 'å‰æ—¥',

            # æˆç¸¾ãƒ»çµæœé–¢é€£
            'çµæœ', 'å‹æ•—', 'æˆç¸¾', 'è¨˜éŒ²', 'æˆæœ', 'å¾—ç‚¹', 'å¤±ç‚¹', 'ãƒ’ãƒƒãƒˆ', 'ã‚¨ãƒ©ãƒ¼',
            'å‹åˆ©', 'æ•—åŒ—', 'å¼•åˆ†', 'å„ªå‹', 'æº–å„ªå‹', 'å…¥è³', 'è¡¨å½°', 'å—è³',

            # å ´æ‰€ãƒ»æ–½è¨­é–¢é€£
            'çƒå ´', 'ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰', 'ä½“è‚²é¤¨', 'é‹å‹•å ´', 'é‡çƒå ´', 'ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«å ´',
            'å­¦æ ¡', 'å°å­¦æ ¡', 'ä¸­å­¦æ ¡', 'é«˜æ ¡', 'å¤§å­¦', 'ä¼šç¤¾', 'è·å ´',

            # ä¸€èˆ¬åè©
            'æƒ…å ±', 'è©³ç´°', 'å…·ä½“', 'ä¸€èˆ¬', 'å…¨ä½“', 'éƒ¨åˆ†', 'å€‹åˆ¥', 'ç‰¹åˆ¥',
            'å†…å®¹', 'è©±é¡Œ', 'å•é¡Œ', 'èª²é¡Œ', 'ç›®æ¨™', 'äºˆå®š', 'è¨ˆç”»', 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«',

            # é¦¬ä¸‰ã‚½ãƒ•ãƒˆé–¢é€£ã®ä¸€èˆ¬èª
            'é¦¬ä¸‰', 'ã‚½ãƒ•ãƒˆ', 'ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«', 'ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢', 'ã‚½ãƒ•ãƒˆã‚¯ãƒªãƒ¼ãƒ ',

            # ã‚ˆãã‚ã‚‹èª¤æŠ½å‡ºèª
            'æ´»èº', 'æˆé•·', 'åŠªåŠ›', 'é ‘å¼µ', 'ä¸Šé”', 'å‘ä¸Š', 'æ”¹å–„', 'ç™ºé”',
            'çµŒé¨“', 'ä½“é¨“', 'ç·´ç¿’', 'è¨“ç·´', 'æŒ‡å°', 'æ•™è‚²', 'å­¦ç¿’', 'å‹‰å¼·'
        }

        # äººåã«ã‚ˆãä½¿ã‚ã‚Œã‚‹æ¼¢å­—
        self.common_name_chars = {
            # å§“ã«ã‚ˆãä½¿ã‚ã‚Œã‚‹æ¼¢å­—
            'ç”°', 'ä¸­', 'ä½', 'è—¤', 'éˆ´', 'æœ¨', 'é«˜', 'æ©‹', 'æ¸¡', 'è¾º', 'ä¼Š', 'å±±', 'æ‘',
            'å°', 'æ—', 'åŠ ', 'å‰', 'æ¾', 'æœ¬', 'äº•', 'ä¸Š', 'æ£®', 'æ± ', 'çŸ³', 'å·',
            'å‰', 'å¾Œ', 'è¥¿', 'æ±', 'å—', 'åŒ—', 'å¤§', 'å°', 'æ–°', 'å¤', 'é•·', 'çŸ­',

            # åã«ã‚ˆãä½¿ã‚ã‚Œã‚‹æ¼¢å­—
            'ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å',
            'å¤ª', 'éƒ', 'æ¬¡', 'é›„', 'ç”·', 'å¤«', 'å­', 'ç¾', 'æµ', 'é¦™', 'èŠ±',
            'æ„›', 'å„ª', 'å¸Œ', 'å…‰', 'è¼', 'æ˜', 'æ¸…', 'æ­£', 'è‰¯', 'å’Œ', 'å¹³',
            'çœŸ', 'èª ', 'ç´”', 'å¥', 'å¼·', 'å‹‡', 'æ™º', 'è³¢', 'è¡', 'å„ª', 'ç§€'
        }

    def search_database_for_additional_players(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰è¿½åŠ é¸æ‰‹ã‚’æ¤œç´¢"""
        print("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¿½åŠ é¸æ‰‹æ¤œç´¢")
        print("=" * 40)

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # å…¨ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            cursor.execute("""
                SELECT content, metadata, timestamp, user_id
                FROM conversation_history
                WHERE content IS NOT NULL AND content != ''
                ORDER BY timestamp DESC
                LIMIT 1000
            """)

            conversations = cursor.fetchall()
            print(f"ğŸ“Š åˆ†æå¯¾è±¡ä¼šè©±æ•°: {len(conversations)} ä»¶")

            # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã§åå‰å€™è£œã‚’æŠ½å‡º
            all_candidates = set()
            pattern_results = {}

            for pattern in self.name_patterns:
                pattern_candidates = set()

                for content, metadata, timestamp, user_id in conversations:
                    text = content or ''
                    matches = re.findall(pattern, text)

                    for match in matches:
                        if self.is_valid_player_name(match):
                            pattern_candidates.add(match)
                            all_candidates.add(match)

                pattern_results[pattern] = pattern_candidates
                print(f"   ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern[:30]}...': {len(pattern_candidates)} å€‹")
                if pattern_candidates:
                    print(f"      ä¾‹: {', '.join(list(pattern_candidates)[:5])}")

            # æ—¢å­˜é¸æ‰‹ã‚’é™¤å¤–ã—ã¦æ–°è¦é¸æ‰‹ã‚’ç‰¹å®š
            for candidate in all_candidates:
                if candidate not in self.existing_players:
                    self.new_players.add(candidate)

            print(f"\nğŸ“Š æŠ½å‡ºçµæœ:")
            print(f"   å…¨å€™è£œ: {len(all_candidates)} å€‹")
            print(f"   æ—¢å­˜é¸æ‰‹: {len(self.existing_players)} å")
            print(f"   æ–°è¦é¸æ‰‹: {len(self.new_players)} å")

            if self.new_players:
                print(f"\nğŸ†• ç™ºè¦‹ã•ã‚ŒãŸæ–°è¦é¸æ‰‹:")
                for player in sorted(self.new_players):
                    print(f"      âœ¨ {player}")

            return all_candidates, pattern_results, conversations

        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return set(), {}, []
        finally:
            if 'conn' in locals():
                conn.close()

    def is_valid_player_name(self, name: str) -> bool:
        """æœ‰åŠ¹ãªé¸æ‰‹åã‹ã©ã†ã‹ã®åˆ¤å®š"""
        # é™¤å¤–èªå½™ãƒã‚§ãƒƒã‚¯
        if name in self.excluded_words:
            return False

        # é•·ã•ãƒã‚§ãƒƒã‚¯ï¼ˆ2-4æ–‡å­—ï¼‰
        if len(name) < 2 or len(name) > 4:
            return False

        # æ¼¢å­—ã®ã¿ã‹ãƒã‚§ãƒƒã‚¯
        if not all('\u4e00' <= c <= '\u9fff' for c in name):
            return False

        # ä¸€èˆ¬çš„ã§ãªã„èªå°¾ã‚’ãƒã‚§ãƒƒã‚¯
        invalid_endings = ['çš„', 'æ€§', 'è€…', 'ç‰©', 'äº‹', 'ä¸­', 'å†…', 'å¤–', 'ä¸Š', 'ä¸‹', 'å‰', 'å¾Œ', 'é–“', 'æ™‚', 'æ—¥', 'æœˆ', 'å¹´']
        if any(name.endswith(ending) for ending in invalid_endings):
            return False

        # äººåã‚‰ã—ã„æ¼¢å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if any(char in self.common_name_chars for char in name):
            return True

        # ãã®ä»–ã®åˆ¤å®šåŸºæº–
        # 3æ–‡å­—ä»¥ä¸Šã§è¤‡é›‘ãªæ¼¢å­—ã®çµ„ã¿åˆã‚ã›ã®å ´åˆã¯äººåã®å¯èƒ½æ€§ãŒé«˜ã„
        if len(name) >= 3:
            return True

        return False

    def analyze_new_players_context(self, conversations: List[tuple]):
        """æ–°è¦é¸æ‰‹ã®æ–‡è„ˆåˆ†æ"""
        print(f"\nğŸ” æ–°è¦é¸æ‰‹æ–‡è„ˆåˆ†æ")
        print("=" * 25)

        player_contexts = {}

        for player in self.new_players:
            contexts = []

            for content, metadata, timestamp, user_id in conversations:
                text = content or ''

                if player in text:
                    # è©²å½“éƒ¨åˆ†ã®å‰å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                    player_index = text.find(player)
                    start = max(0, player_index - 50)
                    end = min(len(text), player_index + len(player) + 50)
                    context = text[start:end]

                    contexts.append({
                        'context': context,
                        'timestamp': timestamp,
                        'user_id': user_id,
                        'full_text': text
                    })

            player_contexts[player] = contexts
            print(f"ğŸ“ {player}: {len(contexts)} ä»¶ã®æ–‡è„ˆ")

            # ä»£è¡¨çš„ãªæ–‡è„ˆã‚’è¡¨ç¤º
            for i, ctx in enumerate(contexts[:3], 1):
                print(f"   {i}. ...{ctx['context']}...")

        return player_contexts

    def create_expanded_player_database(self, player_contexts: Dict):
        """æ‹¡å¼µé¸æ‰‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ"""
        print(f"\nğŸ’¾ æ‹¡å¼µé¸æ‰‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ")
        print("=" * 30)

        # æ—¢å­˜ã®13åã¨æ–°è¦é¸æ‰‹ã‚’çµ±åˆ
        all_players = self.existing_players + sorted(list(self.new_players))

        expanded_database = {
            'team_info': {
                'total_players': len(all_players),
                'original_players': len(self.existing_players),
                'new_players_found': len(self.new_players),
                'team_name': 'é¦¬ä¸‰ã‚½ãƒ•ãƒˆ',
                'last_updated': datetime.now().isoformat()
            },
            'all_players': all_players,
            'original_13_players': self.existing_players,
            'newly_discovered_players': sorted(list(self.new_players)),
            'player_details': []
        }

        # å„é¸æ‰‹ã®è©³ç´°æƒ…å ±
        for i, player in enumerate(all_players, 1):
            player_info = {
                'id': i,
                'name': player,
                'status': 'original' if player in self.existing_players else 'newly_discovered',
                'name_length': len(player),
                'characters': list(player),
                'contexts_found': len(player_contexts.get(player, [])),
                'search_patterns': self.generate_search_patterns(player)
            }

            # æ–°è¦é¸æ‰‹ã®å ´åˆã¯ç™ºè¦‹ã•ã‚ŒãŸæ–‡è„ˆæƒ…å ±ã‚‚å«ã‚ã‚‹
            if player in self.new_players and player in player_contexts:
                player_info['discovery_contexts'] = [
                    ctx['context'] for ctx in player_contexts[player][:5]  # æœ€åˆã®5ä»¶
                ]

            expanded_database['player_details'].append(player_info)

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
        db_path = 'expanded_player_database.json'
        with open(db_path, 'w', encoding='utf-8') as f:
            json.dump(expanded_database, f, ensure_ascii=False, indent=2)

        print(f"âœ… æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜: {db_path}")
        print(f"ğŸ“Š çµ±åˆé¸æ‰‹æ•°: {len(all_players)}å")
        print(f"   - æ—¢å­˜: {len(self.existing_players)}å")
        print(f"   - æ–°è¦: {len(self.new_players)}å")

        return expanded_database

    def generate_search_patterns(self, player_name: str) -> List[str]:
        """æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ"""
        patterns = []

        # åŸºæœ¬ãƒ‘ã‚¿ãƒ¼ãƒ³
        patterns.extend([
            player_name,
            f"{player_name}é¸æ‰‹",
            f"{player_name}å›",
            f"{player_name}ã•ã‚“",
            f"{player_name}ã¡ã‚ƒã‚“",
            f"{player_name}ã«ã¤ã„ã¦",
            f"{player_name}ã®",
            f"{player_name}ã¯",
            f"{player_name}ãŒ",
            f"{player_name}ã‚’",
            f"{player_name}ã«"
        ])

        return patterns

    def create_expanded_response_templates(self, expanded_database: Dict):
        """æ‹¡å¼µå¿œç­”ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ"""
        print(f"\nğŸ“ æ‹¡å¼µå¿œç­”ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ")
        print("=" * 30)

        templates = {}
        all_players = expanded_database['all_players']
        total_players = len(all_players)
        new_players = expanded_database['newly_discovered_players']

        # ãƒãƒ¼ãƒ å…¨ä½“ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆæ›´æ–°ï¼‰
        templates['team_overview'] = f"é¦¬ä¸‰ã‚½ãƒ•ãƒˆã«ã¯{total_players}åã®é¸æ‰‹ãŒå‚åŠ ã—ã¦ã„ã¾ã™ã€‚é¸æ‰‹ä¸€è¦§: {', '.join(all_players)}ã€‚ã©ã®é¸æ‰‹ã«ã¤ã„ã¦è©³ã—ãçŸ¥ã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ"

        templates['player_count'] = f"é¦¬ä¸‰ã‚½ãƒ•ãƒˆã®å‚åŠ é¸æ‰‹ã¯{total_players}åã§ã™ã€‚"

        templates['player_list'] = f"å‚åŠ é¸æ‰‹ä¸€è¦§: {', '.join(all_players)}"

        # æ–°è¦ç™ºè¦‹é¸æ‰‹ã®ç‰¹åˆ¥ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        if new_players:
            templates['new_players_announcement'] = f"æ–°ãŸã«{len(new_players)}åã®é¸æ‰‹ã‚’ç™ºè¦‹ã—ã¾ã—ãŸ: {', '.join(new_players)}"
            templates['discovery_summary'] = f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æã«ã‚ˆã‚Šã€æ—¢å­˜ã®13åã«åŠ ãˆã¦{len(new_players)}åã®è¿½åŠ é¸æ‰‹ã‚’ç™ºè¦‹ã—ã€åˆè¨ˆ{total_players}åã®é¸æ‰‹æƒ…å ±ã‚’å­¦ç¿’ã—ã¾ã—ãŸã€‚"

        # å„é¸æ‰‹ç”¨ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        for player_info in expanded_database['player_details']:
            name = player_info['name']
            position = player_info['id']
            status = player_info['status']

            if status == 'newly_discovered':
                templates[f'{name}_basic'] = f"{name}é¸æ‰‹ã«ã¤ã„ã¦ãŠç­”ãˆã—ã¾ã™ã€‚{name}é¸æ‰‹ã¯æ–°ãŸã«ç™ºè¦‹ã•ã‚ŒãŸé¦¬ä¸‰ã‚½ãƒ•ãƒˆã®ãƒ¡ãƒ³ãƒãƒ¼ã§ã™ã€‚"
                templates[f'{name}_discovery'] = f"{name}é¸æ‰‹ã¯ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã®åˆ†æã«ã‚ˆã‚Šæ–°ãŸã«ç™ºè¦‹ã•ã‚ŒãŸé¸æ‰‹ã§ã™ã€‚"
            else:
                templates[f'{name}_basic'] = f"{name}é¸æ‰‹ã«ã¤ã„ã¦ãŠç­”ãˆã—ã¾ã™ã€‚{name}é¸æ‰‹ã¯é¦¬ä¸‰ã‚½ãƒ•ãƒˆã®{position}ç•ªç›®ã«ç™»éŒ²ã•ã‚ŒãŸé¸æ‰‹ã§ã™ã€‚"

            templates[f'{name}_detail'] = f"{name}é¸æ‰‹ã¯é¦¬ä¸‰ã‚½ãƒ•ãƒˆã®å¤§åˆ‡ãªãƒ¡ãƒ³ãƒãƒ¼ã§ã™ã€‚"
            templates[f'{name}_question'] = f"{name}é¸æ‰‹ã«ã¤ã„ã¦ä½•ã‚’ãŠçŸ¥ã‚Šã«ãªã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ"

        # çµ±è¨ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        templates['statistics'] = f"é¦¬ä¸‰ã‚½ãƒ•ãƒˆã®é¸æ‰‹çµ±è¨ˆ: ç·é¸æ‰‹æ•°{total_players}åï¼ˆæ—¢å­˜{len(expanded_database['original_13_players'])}å + æ–°è¦ç™ºè¦‹{len(new_players)}åï¼‰"

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¿å­˜
        template_path = 'expanded_response_templates.json'
        with open(template_path, 'w', encoding='utf-8') as f:
            json.dump(templates, f, ensure_ascii=False, indent=2)

        print(f"âœ… æ‹¡å¼µãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¿å­˜: {template_path}")
        print(f"ğŸ“Š ä½œæˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ•°: {len(templates)}")

        return templates

    def update_conversation_history(self, expanded_database: Dict):
        """ä¼šè©±å±¥æ­´ã«æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        print(f"\nğŸ’¾ ä¼šè©±å±¥æ­´æ‹¡å¼µæ›´æ–°")
        print("=" * 25)

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            session_id = f'expanded_learning_{datetime.now().strftime("%Y%m%d_%H%M%S")}'

            # æ‹¡å¼µå­¦ç¿’ã®è¨˜éŒ²
            learning_entries = [
                {
                    'user_id': 'system_expansion',
                    'session_id': session_id,
                    'message_type': 'system',
                    'content': f'é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ‹¡å¼µ: ç·é¸æ‰‹æ•°{expanded_database["team_info"]["total_players"]}åï¼ˆæ–°è¦ç™ºè¦‹{len(self.new_players)}åè¿½åŠ ï¼‰',
                    'metadata': json.dumps({
                        'learning_type': 'database_expansion',
                        'total_players': expanded_database["team_info"]["total_players"],
                        'original_players': len(self.existing_players),
                        'new_players': len(self.new_players),
                        'new_player_names': sorted(list(self.new_players)),
                        'source': 'database_analysis'
                    }, ensure_ascii=False),
                    'timestamp': timestamp
                }
            ]

            # æ–°è¦ç™ºè¦‹é¸æ‰‹ã®å€‹åˆ¥ã‚¨ãƒ³ãƒˆãƒªãƒ¼
            for player in self.new_players:
                learning_entries.append({
                    'user_id': 'system_expansion',
                    'session_id': session_id,
                    'message_type': 'system',
                    'content': f'æ–°è¦ç™ºè¦‹é¸æ‰‹: {player}é¸æ‰‹ãŒé¦¬ä¸‰ã‚½ãƒ•ãƒˆã®ãƒ¡ãƒ³ãƒãƒ¼ã¨ã—ã¦ç‰¹å®šã•ã‚Œã¾ã—ãŸã€‚',
                    'metadata': json.dumps({
                        'learning_type': 'new_player_discovery',
                        'player_name': player,
                        'team': 'é¦¬ä¸‰ã‚½ãƒ•ãƒˆ',
                        'discovery_method': 'database_pattern_analysis'
                    }, ensure_ascii=False),
                    'timestamp': timestamp
                })

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æŒ¿å…¥
            for entry in learning_entries:
                cursor.execute("""
                    INSERT INTO conversation_history
                    (user_id, session_id, message_type, content, metadata, timestamp, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    entry['user_id'],
                    entry['session_id'],
                    entry['message_type'],
                    entry['content'],
                    entry['metadata'],
                    entry['timestamp'],
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                ))

            conn.commit()
            print(f"âœ… æ‹¡å¼µå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {len(learning_entries)}ä»¶")

        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            if 'conn' in locals():
                conn.close()

    def generate_expansion_summary(self, expanded_database: Dict):
        """æ‹¡å¼µã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        print(f"\nğŸ“Š æ‹¡å¼µå­¦ç¿’ã‚µãƒãƒªãƒ¼")
        print("=" * 25)

        summary = {
            'expansion_date': datetime.now().isoformat(),
            'original_players': len(self.existing_players),
            'newly_discovered_players': len(self.new_players),
            'total_players_after_expansion': expanded_database['team_info']['total_players'],
            'new_player_names': sorted(list(self.new_players)),
            'expansion_files_created': [
                'expanded_player_database.json',
                'expanded_response_templates.json',
                'player_expansion_summary.json'
            ],
            'discovery_methods': [
                'pattern_matching_analysis',
                'conversation_context_analysis',
                'database_text_mining'
            ]
        }

        print(f"ğŸ“… æ‹¡å¼µå®Ÿè¡Œæ—¥æ™‚: {summary['expansion_date']}")
        print(f"ğŸ“Š æ—¢å­˜é¸æ‰‹æ•°: {summary['original_players']}å")
        print(f"ğŸ†• æ–°è¦ç™ºè¦‹é¸æ‰‹æ•°: {summary['newly_discovered_players']}å")
        print(f"ğŸ† æ‹¡å¼µå¾Œç·é¸æ‰‹æ•°: {summary['total_players_after_expansion']}å")

        if self.new_players:
            print(f"\nğŸŒŸ æ–°è¦ç™ºè¦‹é¸æ‰‹ä¸€è¦§:")
            for i, player in enumerate(sorted(self.new_players), 1):
                print(f"   {i:2d}. {player}")

        # ã‚µãƒãƒªãƒ¼ä¿å­˜
        summary_path = 'player_expansion_summary.json'
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ æ‹¡å¼µã‚µãƒãƒªãƒ¼ä¿å­˜: {summary_path}")

        return summary

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ” è¿½åŠ é¸æ‰‹æŠ½å‡ºãƒ»å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ")
    print(f"ğŸ“… å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
    db_path = os.path.join('..', 'db', 'conversation_history.db')

    if not os.path.exists(db_path):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        return

    # è¿½åŠ é¸æ‰‹æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ 
    extractor = AdditionalPlayerExtractor(db_path)

    print(f"ğŸ“Š æ—¢å­˜é¸æ‰‹: {len(extractor.existing_players)}å")
    print(f"   {', '.join(extractor.existing_players)}")
    print()

    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰è¿½åŠ é¸æ‰‹ã‚’æ¤œç´¢
    all_candidates, pattern_results, conversations = extractor.search_database_for_additional_players()

    if not extractor.new_players:
        print("\nâš ï¸ æ–°è¦é¸æ‰‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        print("   - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ã®é¸æ‰‹æƒ…å ±ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        print("   - æ—¢å­˜ã®13åä»¥å¤–ã®é¸æ‰‹æƒ…å ±ãŒãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        return

    # 2. æ–°è¦é¸æ‰‹ã®æ–‡è„ˆåˆ†æ
    player_contexts = extractor.analyze_new_players_context(conversations)

    # 3. æ‹¡å¼µé¸æ‰‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
    expanded_database = extractor.create_expanded_player_database(player_contexts)

    # 4. æ‹¡å¼µå¿œç­”ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
    templates = extractor.create_expanded_response_templates(expanded_database)

    # 5. ä¼šè©±å±¥æ­´ã«æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ä¿å­˜
    extractor.update_conversation_history(expanded_database)

    # 6. æ‹¡å¼µã‚µãƒãƒªãƒ¼ç”Ÿæˆ
    summary = extractor.generate_expansion_summary(expanded_database)

    print(f"\nğŸ‰ è¿½åŠ é¸æ‰‹æŠ½å‡ºãƒ»å­¦ç¿’å®Œäº†ï¼")
    if extractor.new_players:
        print(f"âœ¨ æ–°è¦ç™ºè¦‹é¸æ‰‹: {', '.join(sorted(extractor.new_players))}")
        print(f"ğŸ“Š æ‹¡å¼µå¾Œç·é¸æ‰‹æ•°: {len(extractor.existing_players) + len(extractor.new_players)}å")
    else:
        print(f"ğŸ“Š æ—¢å­˜é¸æ‰‹ã®ã¿: {len(extractor.existing_players)}å")

if __name__ == "__main__":
    main()

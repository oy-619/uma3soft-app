"""
ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é–¢é€£ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°åˆ†æã¨é¸æ‰‹åå­¦ç¿’å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ 
"""

import sqlite3
import re
import json
from datetime import datetime
from typing import List, Dict, Set
import os

class DetailedSoftballAnalysis:
    """è©³ç´°ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«åˆ†æã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, db_path: str):
        self.db_path = db_path

    def analyze_softball_conversations_detail(self):
        """ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ä¼šè©±ã®è©³ç´°åˆ†æ"""
        print("ğŸ” ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ä¼šè©±è©³ç´°åˆ†æ")
        print("=" * 50)

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # ã‚½ãƒ•ãƒˆé–¢é€£ã®ä¼šè©±ã‚’è©³ç´°å–å¾—
            cursor.execute("""
                SELECT content, metadata, timestamp
                FROM conversation_history
                WHERE content LIKE '%ã‚½ãƒ•ãƒˆ%'
                ORDER BY timestamp DESC
                LIMIT 50
            """)

            softball_conversations = cursor.fetchall()
            print(f"ğŸ“Š 'ã‚½ãƒ•ãƒˆ'ã‚’å«ã‚€ä¼šè©±: {len(softball_conversations)} ä»¶")

            print("\nğŸ“ å®Ÿéš›ã®ä¼šè©±å†…å®¹ã‚µãƒ³ãƒ—ãƒ«:")
            print("-" * 40)

            for i, (content, metadata, timestamp) in enumerate(softball_conversations[:10], 1):
                print(f"{i}. [{timestamp}] {content[:100]}...")
                if metadata:
                    print(f"   ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata[:50]}...")
                print()

            # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            self.analyze_name_patterns(softball_conversations)

            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            self.generate_learning_data(softball_conversations)

            return softball_conversations

        except Exception as e:
            print(f"âŒ è©³ç´°åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return None
        finally:
            if 'conn' in locals():
                conn.close()

    def analyze_name_patterns(self, conversations: List[tuple]):
        """åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°åˆ†æ"""
        print("\nğŸ” åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³è©³ç´°åˆ†æ")
        print("-" * 30)

        # ã‚ˆã‚Šç·©ã„æ¡ä»¶ã§ã®åå‰å€™è£œæŠ½å‡º
        loose_patterns = [
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,6})\s*ã•ã‚“',          # åå‰ ã•ã‚“
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,6})\s*å›',            # åå‰ å›
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,6})\s*ã¡ã‚ƒã‚“',        # åå‰ ã¡ã‚ƒã‚“
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,6})\s*é¸æ‰‹',          # åå‰ é¸æ‰‹
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,6})\s*ãŒ',            # åå‰ ãŒ
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,6})\s*ã¯',            # åå‰ ã¯
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,6})\s*ã‚‚',            # åå‰ ã‚‚
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,6})\s*ã®',            # åå‰ ã®
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,6})\s*ã§',            # åå‰ ã§
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,6})\s*ã¨',            # åå‰ ã¨
        ]

        potential_names = set()
        pattern_stats = {}

        for content, metadata, timestamp in conversations:
            text = content or ''

            for pattern in loose_patterns:
                matches = re.findall(pattern, text)
                if matches:
                    if pattern not in pattern_stats:
                        pattern_stats[pattern] = []

                    pattern_stats[pattern].extend(matches)
                    potential_names.update(matches)

        print(f"ğŸ“Š æ½œåœ¨çš„ãªåå‰å€™è£œ: {len(potential_names)} å€‹")

        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥çµ±è¨ˆ
        for pattern, matches in pattern_stats.items():
            if matches:
                print(f"   ãƒ‘ã‚¿ãƒ¼ãƒ³ {pattern}: {len(set(matches))} å€‹ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯åå‰")
                unique_matches = list(set(matches))[:5]  # æœ€åˆã®5å€‹ã‚’è¡¨ç¤º
                print(f"      ä¾‹: {', '.join(unique_matches)}")

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦äººåã£ã½ã„ã‚‚ã®ã‚’æŠ½å‡º
        filtered_names = self.filter_potential_names(potential_names, conversations)

        return filtered_names

    def filter_potential_names(self, names: Set[str], conversations: List[tuple]) -> Set[str]:
        """äººåå€™è£œã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        print(f"\nğŸ” äººåå€™è£œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
        print("-" * 20)

        filtered_names = set()

        # é™¤å¤–ã™ã‚‹ä¸€èˆ¬çš„ãªå˜èªï¼ˆæ‹¡å¼µç‰ˆï¼‰
        exclude_words = {
            'ã‚½ãƒ•ãƒˆ', 'ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢', 'ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«', 'ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯', 'ã‚½ãƒ•ãƒˆã‚¯ãƒªãƒ¼ãƒ ',
            'ãƒãƒ¼ãƒ ', 'é¸æ‰‹', 'è©¦åˆ', 'ç·´ç¿’', 'å¤§ä¼š', 'ã‚³ãƒ¼ãƒ', 'ç›£ç£', 'å…ˆç”Ÿ',
            'ã§ã™', 'ã¾ã™', 'ã—ãŸ', 'ã™ã‚‹', 'ã‚ã‚‹', 'ãªã‚‹', 'ã„ã‚‹', 'ã‚‚ã®', 'ã“ã¨',
            'ã¨ã', 'ã¨ã“ã‚', 'ãŸã‚', 'ã¯ãš', 'ã‚ã‘', 'ã¤ã‚‚ã‚Š', 'ã»ã†', 'ã¾ã¾',
            'å°å­¦ç”Ÿ', 'ä¸­å­¦ç”Ÿ', 'é«˜æ ¡ç”Ÿ', 'å¤§å­¦ç”Ÿ', 'ç¤¾ä¼šäºº', 'å­ä¾›', 'å¤§äºº',
            'ä»Šæ—¥', 'æ˜æ—¥', 'æ˜¨æ—¥', 'ä»Šå¹´', 'æ¥å¹´', 'å»å¹´', 'æœ€è¿‘', 'ä»Šåº¦',
            'ä¸€ç•ª', 'äºŒç•ª', 'ä¸‰ç•ª', 'æœ€åˆ', 'æœ€å¾Œ', 'å…¨éƒ¨', 'ã¿ã‚“ãª', 'ã ã‚Œ',
            'ãªã«', 'ã©ã“', 'ã„ã¤', 'ã©ã†', 'ãªãœ', 'ã©ã®', 'ãã®', 'ã“ã®', 'ã‚ã®'
        }

        for name in names:
            # é™¤å¤–ãƒã‚§ãƒƒã‚¯
            if name in exclude_words:
                continue

            # é•·ã•ãƒã‚§ãƒƒã‚¯
            if len(name) < 2 or len(name) > 5:
                continue

            # ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠã®ã¿ã¯é™¤å¤–ï¼ˆäººåã¯é€šå¸¸æ¼¢å­—ã‚’å«ã‚€ï¼‰
            if all('ã' <= c <= 'ã‚“' or 'ã‚¡' <= c <= 'ãƒ³' for c in name):
                continue

            # æ•°å­—ã‚„è¨˜å·ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯é™¤å¤–
            if any(c.isdigit() or not c.isalnum() for c in name if c not in 'ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯'):
                continue

            # æ–‡è„ˆã§ã®ä½¿ç”¨å›æ•°ã‚’ãƒã‚§ãƒƒã‚¯
            usage_count = sum(1 for content, _, _ in conversations if name in (content or ''))

            if usage_count >= 1:  # 1å›ä»¥ä¸Šä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹
                filtered_names.add(name)
                print(f"   âœ… å€™è£œæ¡ç”¨: '{name}' (ä½¿ç”¨å›æ•°: {usage_count})")

        print(f"\nğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®åå‰å€™è£œ: {len(filtered_names)} å€‹")
        return filtered_names

    def generate_learning_data(self, conversations: List[tuple]):
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        print(f"\nğŸ“š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ")
        print("-" * 20)

        # ã‚ˆã‚Šè©³ç´°ãªåˆ†æ
        learning_data = {
            'conversation_analysis': [],
            'name_contexts': {},
            'softball_indicators': [],
            'potential_players': []
        }

        # å„ä¼šè©±ã®è©³ç´°åˆ†æ
        for i, (content, metadata, timestamp) in enumerate(conversations[:20]):  # æœ€åˆã®20ä»¶ã‚’è©³ç´°åˆ†æ
            text = content or ''

            analysis = {
                'id': i,
                'content': text,
                'timestamp': timestamp,
                'contains_softball_terms': [],
                'potential_names': [],
                'context_type': 'unknown'
            }

            # ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é–¢é€£ç”¨èªã®æ¤œå‡º
            softball_terms = ['ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«', 'ã‚½ãƒ•ãƒˆ', 'æŠ•æ‰‹', 'ãƒ”ãƒƒãƒãƒ£ãƒ¼', 'é¸æ‰‹', 'ãƒãƒ¼ãƒ ', 'è©¦åˆ', 'ç·´ç¿’', 'ã‚³ãƒ¼ãƒ', 'ç›£ç£']
            for term in softball_terms:
                if term in text:
                    analysis['contains_softball_terms'].append(term)

            # æ½œåœ¨çš„ãªåå‰ã®æ¤œå‡º
            name_patterns = [r'([ä¸€-é¾¯]{2,4})\s*[ã•å›ã¡ã‚ƒã‚“é¸æ‰‹ãŒã¯ã‚‚ã®ã§]']
            for pattern in name_patterns:
                matches = re.findall(pattern, text)
                analysis['potential_names'].extend(matches)

            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¤ãƒ—ã®åˆ¤å®š
            if any(term in text for term in ['ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«', 'ã‚½ãƒ•ãƒˆ']):
                if any(term in text for term in ['é¸æ‰‹', 'æŠ•æ‰‹', 'ãƒãƒ¼ãƒ ']):
                    analysis['context_type'] = 'softball_player_related'
                else:
                    analysis['context_type'] = 'softball_general'

            learning_data['conversation_analysis'].append(analysis)

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        output_path = 'softball_detailed_analysis.json'
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(learning_data, f, ensure_ascii=False, indent=2)

        print(f"âœ… è©³ç´°åˆ†æãƒ‡ãƒ¼ã‚¿ä¿å­˜: {output_path}")

        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        softball_related_count = sum(1 for analysis in learning_data['conversation_analysis']
                                   if analysis['context_type'].startswith('softball'))

        all_potential_names = set()
        for analysis in learning_data['conversation_analysis']:
            all_potential_names.update(analysis['potential_names'])

        print(f"ğŸ“Š è©³ç´°åˆ†æçµæœ:")
        print(f"   ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é–¢é€£ä¼šè©±: {softball_related_count} ä»¶")
        print(f"   æ½œåœ¨çš„åå‰å€™è£œ: {len(all_potential_names)} å€‹")

        if all_potential_names:
            print(f"   å€™è£œä¾‹: {', '.join(list(all_potential_names)[:10])}")

    def create_enhanced_softball_templates(self, potential_names: Set[str]) -> Dict[str, str]:
        """æ‹¡å¼µã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ"""
        print(f"\nğŸ“ æ‹¡å¼µã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ")
        print("-" * 30)

        templates = {}

        # ä¸€èˆ¬çš„ãªã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é–¢é€£ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        general_templates = {
            'ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«': 'âš¾ ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ã«ã¤ã„ã¦ãŠç­”ãˆã—ã¾ã™ã€‚é¸æ‰‹ã€ãƒ«ãƒ¼ãƒ«ã€æˆ¦è¡“ãªã©ã€ã©ã®ã‚ˆã†ãªã“ã¨ã‚’ãŠçŸ¥ã‚Šã«ãªã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ',
            'ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é¸æ‰‹': 'ğŸ¥ ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«é¸æ‰‹ã«ã¤ã„ã¦ã”æ¡ˆå†…ã—ã¾ã™ã€‚ã©ã®é¸æ‰‹ã‚„ã€ã©ã®ã‚ˆã†ãªæƒ…å ±ã‚’ãŠèãã«ãªã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ',
            'ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ãƒãƒ¼ãƒ ': 'ğŸ‘¥ ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ãƒãƒ¼ãƒ ã«ã¤ã„ã¦ãŠè©±ã—ã—ã¾ã™ã€‚ã©ã®ãƒãƒ¼ãƒ ã«ã¤ã„ã¦ãŠçŸ¥ã‚Šã«ãªã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ',
            'ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«è©¦åˆ': 'ğŸŸï¸ ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ã®è©¦åˆã«ã¤ã„ã¦ã”æ¡ˆå†…ã—ã¾ã™ã€‚ã©ã®è©¦åˆã‚„å¤§ä¼šã«ã¤ã„ã¦ãŠèãã«ãªã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ',
            'ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ç·´ç¿’': 'ğŸƒ ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ã®ç·´ç¿’ã«ã¤ã„ã¦ãŠç­”ãˆã—ã¾ã™ã€‚ç·´ç¿’æ–¹æ³•ã‚„ä¸Šé”ã®ã‚³ãƒ„ã«ã¤ã„ã¦ãŠèããã ã•ã„ã€‚',
            'ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ãƒ«ãƒ¼ãƒ«': 'ğŸ“‹ ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ã®ãƒ«ãƒ¼ãƒ«ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚ã©ã®ãƒ«ãƒ¼ãƒ«ã«ã¤ã„ã¦è©³ã—ãçŸ¥ã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ',
            'ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ç”¨å…·': 'ğŸ¥ ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ç”¨å…·ã«ã¤ã„ã¦ã”æ¡ˆå†…ã—ã¾ã™ã€‚ãƒãƒƒãƒˆã€ã‚°ãƒ­ãƒ¼ãƒ–ã€ãƒœãƒ¼ãƒ«ãªã©ã€ã©ã®ç”¨å…·ã«ã¤ã„ã¦ãŠèãã«ãªã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ'
        }

        templates.update(general_templates)

        # æ½œåœ¨çš„é¸æ‰‹åã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        for name in potential_names:
            if len(name) >= 2:
                templates[f'{name}é¸æ‰‹'] = f'{name}é¸æ‰‹ã«ã¤ã„ã¦ãŠè©±ã—ã—ã¾ã™ã€‚ã©ã®ã‚ˆã†ãªã“ã¨ã‚’ãŠçŸ¥ã‚Šã«ãªã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ'
                templates[f'{name}ã«ã¤ã„ã¦'] = f'{name}ã«ã¤ã„ã¦ã”æ¡ˆå†…ã—ã¾ã™ã€‚ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ã«é–¢ã™ã‚‹ã“ã¨ã§ã—ãŸã‚‰ãŠèããã ã•ã„ã€‚'

        print(f"âœ… ä½œæˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ•°: {len(templates)}")
        return templates

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ¥ è©³ç´°ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    print(f"ğŸ“… å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
    db_path = os.path.join('..', 'db', 'conversation_history.db')

    if not os.path.exists(db_path):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        return

    # è©³ç´°åˆ†æã‚·ã‚¹ãƒ†ãƒ 
    analyzer = DetailedSoftballAnalysis(db_path)

    # 1. è©³ç´°åˆ†æå®Ÿè¡Œ
    conversations = analyzer.analyze_softball_conversations_detail()

    if not conversations:
        print("âŒ è©³ç´°åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
        return

    # 2. åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    potential_names = analyzer.analyze_name_patterns(conversations)

    # 3. æ‹¡å¼µãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
    templates = analyzer.create_enhanced_softball_templates(potential_names)

    # 4. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¿å­˜
    templates_path = 'enhanced_softball_templates.json'
    with open(templates_path, 'w', encoding='utf-8') as f:
        json.dump(templates, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ æ‹¡å¼µãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¿å­˜: {templates_path}")

    # 5. æœ€çµ‚ã‚µãƒãƒªãƒ¼
    print(f"\nğŸ“Š è©³ç´°åˆ†ææœ€çµ‚çµæœ")
    print("-" * 40)
    print(f"   ğŸ” åˆ†æã—ãŸä¼šè©±æ•°: {len(conversations)}")
    print(f"   ğŸ‘¤ æ½œåœ¨çš„é¸æ‰‹åå€™è£œ: {len(potential_names)}")
    print(f"   ğŸ“ ä½œæˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {len(templates)}")

    if potential_names:
        print(f"\nğŸ†• ç™ºè¦‹ã•ã‚ŒãŸåå‰å€™è£œ:")
        for name in sorted(potential_names):
            print(f"      ğŸ” {name}")

    print(f"\nğŸ‰ è©³ç´°ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«åˆ†æå®Œäº†ï¼")

if __name__ == "__main__":
    main()

"""
DBã®é…è»Šæƒ…å ±ã‹ã‚‰é¸æ‰‹ã®åå‰ã‚’å­¦ç¿’ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import sqlite3
import re
import json
from datetime import datetime
from typing import List, Dict, Set
import os

class PlayerNameLearningSystem:
    """é…è»Šæƒ…å ±ã‹ã‚‰é¸æ‰‹åã‚’å­¦ç¿’ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, db_path: str):
        self.db_path = db_path
        self.learned_names = set()
        self.name_patterns = []

    def analyze_conversation_database(self):
        """ä¼šè©±ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆ†æã—ã¦é…è»Šæƒ…å ±ã‚’æŠ½å‡º"""
        print("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æé–‹å§‹")
        print("=" * 50)

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ç¢ºèª
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = cursor.fetchall()
            print(f"ğŸ“Š åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«: {[table[0] for table in tables]}")

            # ä¼šè©±å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
            if ('conversation_history',) in tables:
                cursor.execute("PRAGMA table_info(conversation_history)")
                columns = cursor.fetchall()
                print(f"ğŸ“‹ conversation_historyã‚«ãƒ©ãƒ : {[col[1] for col in columns]}")

                # é…è»Šé–¢é€£ã®ä¼šè©±ã‚’æ¤œç´¢ï¼ˆå®Ÿéš›ã®DBã‚¹ã‚­ãƒ¼ãƒã«åˆã‚ã›ã¦ä¿®æ­£ï¼‰
                cursor.execute("""
                    SELECT content, metadata, timestamp
                    FROM conversation_history
                    WHERE content LIKE '%é…è»Š%'
                       OR content LIKE '%é¸æ‰‹%'
                       OR content LIKE '%é¨æ‰‹%'
                       OR content LIKE '%åå‰%'
                       OR content LIKE '%ãƒ‰ãƒ©ã‚¤ãƒãƒ¼%'
                       OR content LIKE '%ç«¶é¦¬%'
                    ORDER BY timestamp DESC
                    LIMIT 100
                """)

                dispatching_conversations = cursor.fetchall()
                print(f"ğŸš— é…è»Šé–¢é€£ä¼šè©±æ•°: {len(dispatching_conversations)}")

                # é¸æ‰‹åæŠ½å‡º
                extracted_names = self.extract_player_names_from_conversations(dispatching_conversations)

                return {
                    'dispatching_conversations': dispatching_conversations,
                    'extracted_names': extracted_names,
                    'total_conversations': len(dispatching_conversations)
                }

        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return None
        finally:
            if 'conn' in locals():
                conn.close()

    def extract_player_names_from_conversations(self, conversations: List[tuple]) -> Set[str]:
        """ä¼šè©±ã‹ã‚‰é¸æ‰‹åã‚’æŠ½å‡ºï¼ˆDBæ§‹é€ ã«åˆã‚ã›ã¦ä¿®æ­£ï¼‰"""
        print("\nğŸ‡ é¸æ‰‹åæŠ½å‡ºå‡¦ç†")
        print("-" * 30)

        extracted_names = set()

        # æ—¥æœ¬ã®ä¸€èˆ¬çš„ãªå§“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        common_surnames = [
            'ç”°ä¸­', 'ä½è—¤', 'éˆ´æœ¨', 'é«˜æ©‹', 'æ¸¡è¾º', 'ä¼Šè—¤', 'å±±ç”°', 'ä¸­æ‘', 'å°æ—', 'åŠ è—¤',
            'å‰ç”°', 'å±±æœ¬', 'æ–è—¤', 'æ¾æœ¬', 'äº•ä¸Š', 'æœ¨æ‘', 'æ—', 'æ¸…æ°´', 'å±±å´', 'æ± ç”°',
            'æ©‹æœ¬', 'çŸ³ç”°', 'ä¸­å³¶', 'å‰ç”°', 'è—¤ç”°', 'å¾Œè—¤', 'å²¡ç”°', 'é•·è°·å·', 'çŸ³å·', 'è¿‘è—¤'
        ]

        # ç«¶é¦¬é–¢é€£ã®æœ‰åé¨æ‰‹åï¼ˆä¾‹ï¼‰
        famous_jockeys = [
            'æ­¦è±Š', 'ç¦æ°¸ç¥ä¸€', 'å·ç”°å°†é›…', 'æˆ¸å´åœ­å¤ª', 'å²©ç”°åº·èª ', 'æ± æ·»è¬™ä¸€', 'å’Œç”°ç«œäºŒ',
            'è—¤å²¡åº·å¤ª', 'æ¾å±±å¼˜å¹³', 'é®«å³¶å…‹é§¿', 'ä¸¸å±±å…ƒæ°—', 'æ¨ªå±±å…¸å¼˜', 'è›¯åæ­£ç¾©', 'å†…ç”°åšå¹¸'
        ]

        # åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©
        name_patterns = [
            r'é¸æ‰‹[ï¼š:]\s*([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³\s]{2,8})',  # é¸æ‰‹: åå‰
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,4})\s*é¸æ‰‹',          # åå‰ é¸æ‰‹
            r'é¨æ‰‹[ï¼š:]\s*([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³\s]{2,8})',    # é¨æ‰‹: åå‰
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,4})\s*é¨æ‰‹',          # åå‰ é¨æ‰‹
            r'é…è»Š[ï¼š:]\s*([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³\s]{2,8})',    # é…è»Š: åå‰
            r'ãƒ‰ãƒ©ã‚¤ãƒãƒ¼[ï¼š:]\s*([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³\s]{2,8})', # ãƒ‰ãƒ©ã‚¤ãƒãƒ¼: åå‰
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,4})\s*ã•ã‚“',           # åå‰ ã•ã‚“
            r'([ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{2,4})\s*å›',             # åå‰ å›
        ]

        # æœ‰åé¨æ‰‹åã®ç›´æ¥æ¤œç´¢
        all_known_names = set(famous_jockeys)

        for content, metadata, timestamp in conversations:
            text_content = content or ''

            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã§æŠ½å‡º
            for pattern in name_patterns:
                matches = re.findall(pattern, text_content)
                for match in matches:
                    name = match.strip()
                    if len(name) >= 2 and len(name) <= 8:
                        extracted_names.add(name)
                        print(f"   ğŸ“ ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰æŠ½å‡º: '{name}'")

            # æœ‰åé¨æ‰‹åã®ç›´æ¥æ¤œç´¢
            for jockey in famous_jockeys:
                if jockey in text_content:
                    extracted_names.add(jockey)
                    print(f"   ğŸ† æœ‰åé¨æ‰‹åæ¤œå‡º: '{jockey}'")

            # ä¸€èˆ¬çš„ãªå§“ã‚’å«ã‚€åå‰ã®ç‰¹åˆ¥å‡¦ç†
            for surname in common_surnames:
                # å§“ + åã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                pattern = f'{surname}[ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ³]{{1,3}}'
                matches = re.findall(pattern, text_content)
                for match in matches:
                    if len(match) >= 3 and len(match) <= 6:
                        extracted_names.add(match)
                        print(f"   ğŸ‘¤ å§“åãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰æŠ½å‡º: '{match}'")

        print(f"\nğŸ“Š æŠ½å‡ºã•ã‚ŒãŸé¸æ‰‹åç·æ•°: {len(extracted_names)}")
        return extracted_names

    def learn_player_names(self, extracted_names: Set[str]) -> Dict:
        """æŠ½å‡ºã•ã‚ŒãŸé¸æ‰‹åã‚’å­¦ç¿’"""
        print("\nğŸ§  é¸æ‰‹åå­¦ç¿’å‡¦ç†")
        print("-" * 30)

        learning_results = {
            'learned_names': list(extracted_names),
            'name_categories': {
                'jockey_names': [],      # é¨æ‰‹å
                'driver_names': [],      # ãƒ‰ãƒ©ã‚¤ãƒãƒ¼å
                'general_names': []      # ä¸€èˆ¬çš„ãªåå‰
            },
            'name_patterns': [],
            'confidence_scores': {}
        }

        # åå‰ã®åˆ†é¡ã¨ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
        for name in extracted_names:
            confidence = self.calculate_name_confidence(name)
            learning_results['confidence_scores'][name] = confidence

            # é«˜ã„ä¿¡é ¼åº¦ã®åå‰ã‚’åˆ†é¡
            if confidence >= 0.7:
                learning_results['name_categories']['general_names'].append(name)
                print(f"   âœ… å­¦ç¿’å®Œäº†: '{name}' (ä¿¡é ¼åº¦: {confidence:.2f})")
            else:
                print(f"   âš ï¸ ä½ä¿¡é ¼åº¦: '{name}' (ä¿¡é ¼åº¦: {confidence:.2f})")

        # åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç”Ÿæˆ
        learning_results['name_patterns'] = self.generate_name_patterns(extracted_names)

        return learning_results

    def calculate_name_confidence(self, name: str) -> float:
        """åå‰ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—"""
        confidence = 0.5  # åŸºæœ¬ä¿¡é ¼åº¦

        # é•·ã•ã«ã‚ˆã‚‹èª¿æ•´
        if 2 <= len(name) <= 4:
            confidence += 0.3
        elif len(name) == 5:
            confidence += 0.1
        else:
            confidence -= 0.2

        # æ¼¢å­—ã®å‰²åˆ
        kanji_count = len([c for c in name if '\u4e00' <= c <= '\u9faf'])
        if kanji_count >= len(name) * 0.5:
            confidence += 0.2

        # ä¸€èˆ¬çš„ã§ãªã„æ–‡å­—ã®æ¤œå‡º
        if any(c in name for c in ['è»Š', 'é…', 'é¸æ‰‹', 'é¨æ‰‹', 'ãƒ‰ãƒ©ã‚¤ãƒãƒ¼']):
            confidence -= 0.4

        return max(0.0, min(1.0, confidence))

    def generate_name_patterns(self, names: Set[str]) -> List[str]:
        """åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆ"""
        patterns = []

        for name in names:
            # åå‰ã®ç›´å‰ãƒ»ç›´å¾Œã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³
            patterns.extend([
                f'{name}é¸æ‰‹',
                f'{name}é¨æ‰‹',
                f'{name}ã•ã‚“',
                f'é¸æ‰‹{name}',
                f'é¨æ‰‹{name}',
                f'{name}ã®é…è»Š',
                f'{name}ã«ã¤ã„ã¦'
            ])

        return list(set(patterns))

    def save_learned_names(self, learning_results: Dict, output_path: str):
        """å­¦ç¿’çµæœã‚’ä¿å­˜"""
        print(f"\nğŸ’¾ å­¦ç¿’çµæœä¿å­˜: {output_path}")

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¿½åŠ 
        learning_results['learning_timestamp'] = datetime.now().isoformat()
        learning_results['total_learned_names'] = len(learning_results['learned_names'])

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(learning_results, f, ensure_ascii=False, indent=2)

        print(f"âœ… ä¿å­˜å®Œäº†: {len(learning_results['learned_names'])}å€‹ã®é¸æ‰‹åã‚’å­¦ç¿’")

    def integrate_with_response_system(self, learning_results: Dict):
        """æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ"""
        print(f"\nğŸ”— å¿œç­”ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ")
        print("-" * 30)

        try:
            # æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            import sys
            tests_path = os.path.join(os.path.dirname(__file__), '..', 'tests')
            sys.path.insert(0, tests_path)

            from improved_response_system import ImprovedResponseGenerator

            # é¸æ‰‹åã‚’ä½¿ã£ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ‹¡å¼µ
            player_templates = {}

            for name in learning_results['learned_names']:
                if learning_results['confidence_scores'].get(name, 0) >= 0.7:
                    player_templates[f'{name}ã«ã¤ã„ã¦'] = f'{name}é¸æ‰‹ã«ã¤ã„ã¦ãŠè©±ã—ã—ã¾ã™ã€‚ä½•ã‹å…·ä½“çš„ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ'
                    player_templates[f'{name}ã®é…è»Š'] = f'{name}é¸æ‰‹ã®é…è»Šã«ã¤ã„ã¦ã”æ¡ˆå†…ã—ã¾ã™ã€‚'
                    player_templates[f'{name}é¸æ‰‹'] = f'{name}é¸æ‰‹ã®ã“ã¨ã§ã™ã­ã€‚ã©ã®ã‚ˆã†ãªã“ã¨ã‚’ãŠèãã«ãªã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ'

            print(f"ğŸ“ ä½œæˆã•ã‚ŒãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ•°: {len(player_templates)}")

            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¿å­˜
            template_path = os.path.join(os.path.dirname(__file__), '..', 'tests', 'player_name_templates.json')
            with open(template_path, 'w', encoding='utf-8') as f:
                json.dump(player_templates, f, ensure_ascii=False, indent=2)

            print(f"âœ… é¸æ‰‹åãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¿å­˜: {template_path}")

            return player_templates

        except Exception as e:
            print(f"âŒ çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            return {}

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ‡ é…è»Šæƒ…å ±é¸æ‰‹åå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ")
    print(f"ğŸ“… å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
    db_path = os.path.join('..', 'db', 'conversation_history.db')

    if not os.path.exists(db_path):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        return

    # å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    learning_system = PlayerNameLearningSystem(db_path)

    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æ
    analysis_result = learning_system.analyze_conversation_database()

    if not analysis_result:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
        return

    # 2. é¸æ‰‹åå­¦ç¿’
    learning_results = learning_system.learn_player_names(analysis_result['extracted_names'])

    # 3. å­¦ç¿’çµæœä¿å­˜
    output_path = os.path.join('..', 'tests', 'learned_player_names.json')
    learning_system.save_learned_names(learning_results, output_path)

    # 4. å¿œç­”ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
    player_templates = learning_system.integrate_with_response_system(learning_results)

    # 5. çµæœã‚µãƒãƒªãƒ¼
    print(f"\nğŸ“Š å­¦ç¿’çµæœã‚µãƒãƒªãƒ¼")
    print("-" * 40)
    print(f"   ğŸ¯ åˆ†æã—ãŸä¼šè©±æ•°: {analysis_result['total_conversations']}")
    print(f"   ğŸ‘¤ æŠ½å‡ºã•ã‚ŒãŸé¸æ‰‹å: {len(analysis_result['extracted_names'])}")
    print(f"   ğŸ“š å­¦ç¿’ã—ãŸé¸æ‰‹å: {len(learning_results['learned_names'])}")
    print(f"   âœ… é«˜ä¿¡é ¼åº¦é¸æ‰‹å: {len([n for n, c in learning_results['confidence_scores'].items() if c >= 0.7])}")
    print(f"   ğŸ“ ä½œæˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {len(player_templates)}")

    # é«˜ä¿¡é ¼åº¦ã®é¸æ‰‹åã‚’è¡¨ç¤º
    high_confidence_names = [
        name for name, confidence in learning_results['confidence_scores'].items()
        if confidence >= 0.7
    ]

    if high_confidence_names:
        print(f"\nğŸ† é«˜ä¿¡é ¼åº¦é¸æ‰‹å:")
        for name in sorted(high_confidence_names):
            confidence = learning_results['confidence_scores'][name]
            print(f"      {name} (ä¿¡é ¼åº¦: {confidence:.2f})")

    print(f"\nğŸ‰ é¸æ‰‹åå­¦ç¿’å®Œäº†ï¼")

if __name__ == "__main__":
    main()

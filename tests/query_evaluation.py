"""
ChromaDBæ¤œç´¢çµæœã¨LLMå›ç­”ã®è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
ã€Œä»Šé€±æœ«ã®ç·´ç¿’äºˆå®šã¨è©¦åˆäºˆå®šã‚’ã—ãˆã¦ãã ã•ã„ã€‚ã€ã‚¯ã‚¨ãƒªã®è©³ç´°åˆ†æ
"""

import sys
import os
import time
from datetime import datetime

sys.path.append(".")

from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from uma3_chroma_improver import Uma3ChromaDBImprover


def evaluate_query_response():
    """æŒ‡å®šã‚¯ã‚¨ãƒªã®æ¤œç´¢çµæœã¨LLMå›ç­”ã‚’è©³ç´°è©•ä¾¡"""
    print("=" * 80)
    print("ğŸ” ChromaDBæ¤œç´¢çµæœã¨LLMå›ç­”ã®è©³ç´°è©•ä¾¡")
    print("=" * 80)

    # è©•ä¾¡å¯¾è±¡ã‚¯ã‚¨ãƒª
    target_query = "ä»Šé€±æœ«ã®ç·´ç¿’äºˆå®šã¨è©¦åˆäºˆå®šã‚’ã—ãˆã¦ãã ã•ã„ã€‚"
    test_user = "è©•ä¾¡ç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼"

    print(f"ğŸ“‹ è©•ä¾¡å¯¾è±¡ã‚¯ã‚¨ãƒª: '{target_query}'")
    print(f"ğŸ” å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ‘¤ ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼: {test_user}")

    # åˆæœŸåŒ–
    embedding_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    vector_db = Chroma(
        persist_directory="../chroma_store",
        embedding_function=embedding_model
    )
    improver = Uma3ChromaDBImprover(vector_db)

    # OpenAIè¨­å®š
    # ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
    from dotenv import load_dotenv
    load_dotenv()
    
    # OpenAI APIè¨­å®šã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
    if not os.getenv("OPENAI_API_KEY"):
        raise ValueError("OPENAI_API_KEY environment variable is not set")

    print("\n" + "=" * 60)
    print("ğŸ“Š STEP 1: ChromaDBæ¤œç´¢çµæœã®è©³ç´°åˆ†æ")
    print("=" * 60)

    # 1. åŸºæœ¬æ¤œç´¢
    print("\nğŸ” 1-1. åŸºæœ¬æ¤œç´¢çµæœ")
    print("-" * 40)

    start_time = time.time()
    basic_results = vector_db.similarity_search_with_score(target_query, k=10)
    basic_time = time.time() - start_time

    print(f"æ¤œç´¢æ™‚é–“: {basic_time:.3f}ç§’")
    print(f"çµæœä»¶æ•°: {len(basic_results)}ä»¶")

    if basic_results:
        print("\nğŸ“‹ åŸºæœ¬æ¤œç´¢çµæœè©³ç´°:")
        for i, (doc, score) in enumerate(basic_results, 1):
            content_preview = doc.page_content[:60].replace('\n', ' ')
            user = doc.metadata.get('user', 'Unknown')
            timestamp = doc.metadata.get('timestamp', 'Unknown')
            print(f"  {i:2d}. ã‚¹ã‚³ã‚¢: {score:.4f} | ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user}")
            print(f"      æ™‚ç³»åˆ—: {timestamp}")
            print(f"      å†…å®¹: {content_preview}...")
            print()

    # 2. ã‚¹ãƒãƒ¼ãƒˆæ¤œç´¢
    print("\nğŸ§  1-2. ã‚¹ãƒãƒ¼ãƒˆæ¤œç´¢çµæœï¼ˆæ”¹å–„ç‰ˆï¼‰")
    print("-" * 40)

    start_time = time.time()
    smart_results = improver.smart_similarity_search(
        target_query,
        k=10,
        user_id=test_user,
        boost_recent=True,
        score_threshold=0.5
    )
    smart_time = time.time() - start_time

    print(f"æ¤œç´¢æ™‚é–“: {smart_time:.3f}ç§’")
    print(f"çµæœä»¶æ•°: {len(smart_results)}ä»¶")
    print(f"é€Ÿåº¦æ¯”è¼ƒ: {((smart_time - basic_time) / basic_time) * 100:+.1f}%")

    if smart_results:
        print("\nğŸ“‹ ã‚¹ãƒãƒ¼ãƒˆæ¤œç´¢çµæœè©³ç´°:")
        for i, doc in enumerate(smart_results, 1):
            content_preview = doc.page_content[:60].replace('\n', ' ')
            user = doc.metadata.get('user', 'Unknown')
            timestamp = doc.metadata.get('timestamp', 'Unknown')
            print(f"  {i:2d}. ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user} | æ™‚ç³»åˆ—: {timestamp}")
            print(f"      å†…å®¹: {content_preview}...")
            print()

    # 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢
    print("\nğŸ¯ 1-3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢çµæœ")
    print("-" * 40)

    start_time = time.time()
    context_results = improver.get_contextual_search(target_query, test_user, k=5)
    context_time = time.time() - start_time

    print(f"æ¤œç´¢æ™‚é–“: {context_time:.3f}ç§’")
    print(f"çµæœä»¶æ•°: {len(context_results)}ä»¶")

    if context_results:
        print("\nğŸ“‹ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢çµæœè©³ç´°:")
        for i, doc in enumerate(context_results, 1):
            content_preview = doc.page_content[:60].replace('\n', ' ')
            user = doc.metadata.get('user', 'Unknown')
            timestamp = doc.metadata.get('timestamp', 'Unknown')
            print(f"  {i:2d}. ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user} | æ™‚ç³»åˆ—: {timestamp}")
            print(f"      å†…å®¹: {content_preview}...")
            print()

    # 4. æ¤œç´¢çµæœã®é–¢é€£æ€§è©•ä¾¡
    print("\nğŸ“ˆ 1-4. æ¤œç´¢çµæœã®é–¢é€£æ€§è©•ä¾¡")
    print("-" * 40)

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
    target_keywords = ['ç·´ç¿’', 'äºˆå®š', 'è©¦åˆ', 'ä»Šé€±æœ«', 'é€±æœ«', 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«', 'æ—¥ç¨‹']

    def analyze_relevance(results, result_type):
        if not results:
            return {"relevance_score": 0, "keyword_matches": 0, "total_results": 0}

        total_keyword_matches = 0
        relevant_results = 0

        # çµæœã®å½¢å¼ã«å¿œã˜ã¦å‡¦ç†
        docs = []
        if isinstance(results[0], tuple):  # (doc, score)ã®å½¢å¼
            docs = [doc for doc, score in results]
        else:  # docã®ã¿ã®å½¢å¼
            docs = results

        for doc in docs:
            content = doc.page_content.lower()
            keyword_matches = sum(1 for keyword in target_keywords if keyword in content)
            total_keyword_matches += keyword_matches

            if keyword_matches > 0:
                relevant_results += 1

        relevance_score = (relevant_results / len(docs)) * 100 if docs else 0
        avg_keyword_matches = total_keyword_matches / len(docs) if docs else 0

        print(f"{result_type}:")
        print(f"  é–¢é€£æ€§ã‚¹ã‚³ã‚¢: {relevance_score:.1f}% ({relevant_results}/{len(docs)}ä»¶)")
        print(f"  å¹³å‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´: {avg_keyword_matches:.1f}å€‹/ä»¶")
        print(f"  ç·ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´: {total_keyword_matches}å€‹")

        return {
            "relevance_score": relevance_score,
            "keyword_matches": total_keyword_matches,
            "total_results": len(docs),
            "relevant_results": relevant_results
        }    # å„æ¤œç´¢æ–¹æ³•ã®é–¢é€£æ€§è©•ä¾¡
    basic_analysis = analyze_relevance(
        [(doc, score) for doc, score in basic_results], "åŸºæœ¬æ¤œç´¢"
    )
    smart_analysis = analyze_relevance(smart_results, "ã‚¹ãƒãƒ¼ãƒˆæ¤œç´¢")
    context_analysis = analyze_relevance(context_results, "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢")

    print("\n" + "=" * 60)
    print("ğŸ¤– STEP 2: LLMå›ç­”ç”Ÿæˆã¨è©•ä¾¡")
    print("=" * 60)

    # LLMåˆæœŸåŒ–
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.3,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )

    # å„æ¤œç´¢çµæœã§LLMå›ç­”ã‚’ç”Ÿæˆ
    def generate_llm_response(search_results, search_type):
        print(f"\nğŸ§  2-{search_type}. {search_type}çµæœã‚’ä½¿ç”¨ã—ãŸLLMå›ç­”")
        print("-" * 40)

        if not search_results:
            print("æ¤œç´¢çµæœãªã— - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—ã§å›ç­”ç”Ÿæˆ")
            prompt_template = ChatPromptTemplate.from_messages([
                ("system", "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
                ("human", "{input}")
            ])
            prompt = prompt_template.format(input=target_query)
        else:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
            if isinstance(search_results[0], tuple):  # (doc, score) ã®å ´åˆ
                context_parts = [doc.page_content for doc, score in search_results[:5]]
            else:  # doc ã®ã¿ã®å ´åˆ
                context_parts = [doc.page_content for doc in search_results[:5]]

            context = "\n".join(context_parts)

            prompt_template = ChatPromptTemplate.from_messages([
                ("system", "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®éå»ã®ä¼šè©±å±¥æ­´ã‚’å‚è€ƒã«ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n---\n{context}\n---"),
                ("human", "{input}")
            ])
            prompt = prompt_template.format(context=context, input=target_query)

        # LLMå›ç­”ç”Ÿæˆ
        start_time = time.time()
        response = llm.invoke(prompt)
        generation_time = time.time() - start_time

        answer = response.content

        print(f"ç”Ÿæˆæ™‚é–“: {generation_time:.3f}ç§’")
        print(f"å›ç­”æ–‡å­—æ•°: {len(answer)}æ–‡å­—")
        print(f"\nğŸ¤– LLMå›ç­”:")
        print("-" * 30)
        print(answer)
        print("-" * 30)

        # å›ç­”å“è³ªè©•ä¾¡
        answer_lower = answer.lower()
        answer_keywords = sum(1 for keyword in target_keywords if keyword in answer_lower)

        # å…·ä½“æ€§ãƒã‚§ãƒƒã‚¯
        specific_indicators = ['æ™‚é–“', 'å ´æ‰€', 'æ—¥æ™‚', 'æ›œæ—¥', 'æœˆ', 'æ—¥', 'æ™‚', 'åˆ†']
        specificity_score = sum(1 for indicator in specific_indicators if indicator in answer)

        # æœ‰ç”¨æ€§è©•ä¾¡
        helpful_phrases = ['äºˆå®š', 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«', 'ç¢ºèª', 'è©³ç´°', 'æƒ…å ±']
        helpfulness_score = sum(1 for phrase in helpful_phrases if phrase in answer)

        print(f"\nğŸ“Š å›ç­”å“è³ªè©•ä¾¡:")
        print(f"  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´: {answer_keywords}/{len(target_keywords)} ({(answer_keywords/len(target_keywords))*100:.1f}%)")
        print(f"  å…·ä½“æ€§ã‚¹ã‚³ã‚¢: {specificity_score}/8 ({(specificity_score/8)*100:.1f}%)")
        print(f"  æœ‰ç”¨æ€§ã‚¹ã‚³ã‚¢: {helpfulness_score}/5 ({(helpfulness_score/5)*100:.1f}%)")

        return {
            "answer": answer,
            "generation_time": generation_time,
            "answer_length": len(answer),
            "keyword_matches": answer_keywords,
            "specificity_score": specificity_score,
            "helpfulness_score": helpfulness_score
        }

    # å„æ¤œç´¢æ–¹æ³•ã§ã®LLMå›ç­”ç”Ÿæˆ
    basic_llm = generate_llm_response(basic_results, "1: åŸºæœ¬æ¤œç´¢")
    smart_llm = generate_llm_response(smart_results, "2: ã‚¹ãƒãƒ¼ãƒˆæ¤œç´¢")
    context_llm = generate_llm_response(context_results, "3: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢")

    print("\n" + "=" * 60)
    print("ğŸ“ˆ STEP 3: ç·åˆè©•ä¾¡ã¨æ¯”è¼ƒåˆ†æ")
    print("=" * 60)

    # ç·åˆè©•ä¾¡
    print("\nğŸ† 3-1. æ¤œç´¢æ–¹æ³•åˆ¥ç·åˆè©•ä¾¡")
    print("-" * 40)

    methods = [
        ("åŸºæœ¬æ¤œç´¢", basic_analysis, basic_llm, basic_time),
        ("ã‚¹ãƒãƒ¼ãƒˆæ¤œç´¢", smart_analysis, smart_llm, smart_time),
        ("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢", context_analysis, context_llm, context_time)
    ]

    best_scores = {"relevance": 0, "keywords": 0, "specificity": 0, "helpfulness": 0}

    for method_name, search_analysis, llm_result, search_time in methods:
        print(f"\n{method_name}:")
        print(f"  ğŸ” æ¤œç´¢æ€§èƒ½:")
        print(f"    - æ¤œç´¢æ™‚é–“: {search_time:.3f}ç§’")
        print(f"    - çµæœä»¶æ•°: {search_analysis['total_results']}ä»¶")
        print(f"    - é–¢é€£æ€§: {search_analysis['relevance_score']:.1f}%")

        print(f"  ğŸ¤– LLMå›ç­”å“è³ª:")
        print(f"    - ç”Ÿæˆæ™‚é–“: {llm_result['generation_time']:.3f}ç§’")
        print(f"    - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´: {llm_result['keyword_matches']}/{len(target_keywords)}")
        print(f"    - å…·ä½“æ€§: {llm_result['specificity_score']}/8")
        print(f"    - æœ‰ç”¨æ€§: {llm_result['helpfulness_score']}/5")

        # ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢æ›´æ–°
        if search_analysis['relevance_score'] > best_scores["relevance"]:
            best_scores["relevance"] = search_analysis['relevance_score']
        if llm_result['keyword_matches'] > best_scores["keywords"]:
            best_scores["keywords"] = llm_result['keyword_matches']
        if llm_result['specificity_score'] > best_scores["specificity"]:
            best_scores["specificity"] = llm_result['specificity_score']
        if llm_result['helpfulness_score'] > best_scores["helpfulness"]:
            best_scores["helpfulness"] = llm_result['helpfulness_score']

    # æ¨å¥¨æ–¹æ³•ã®æ±ºå®š
    print(f"\nğŸ¥‡ 3-2. æ¨å¥¨æ–¹æ³•ã¨æ”¹å–„ææ¡ˆ")
    print("-" * 40)

    # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
    method_scores = []
    for method_name, search_analysis, llm_result, search_time in methods:
        # æ­£è¦åŒ–ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆ0-100ï¼‰
        relevance_norm = (search_analysis['relevance_score'] / best_scores["relevance"]) * 100 if best_scores["relevance"] > 0 else 0
        keywords_norm = (llm_result['keyword_matches'] / best_scores["keywords"]) * 100 if best_scores["keywords"] > 0 else 0
        specificity_norm = (llm_result['specificity_score'] / best_scores["specificity"]) * 100 if best_scores["specificity"] > 0 else 0
        helpfulness_norm = (llm_result['helpfulness_score'] / best_scores["helpfulness"]) * 100 if best_scores["helpfulness"] > 0 else 0

        # é‡ã¿ä»˜ãç·åˆã‚¹ã‚³ã‚¢
        total_score = (relevance_norm * 0.3 + keywords_norm * 0.25 +
                      specificity_norm * 0.25 + helpfulness_norm * 0.2)

        method_scores.append((method_name, total_score, {
            'relevance': relevance_norm,
            'keywords': keywords_norm,
            'specificity': specificity_norm,
            'helpfulness': helpfulness_norm
        }))

    # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
    method_scores.sort(key=lambda x: x[1], reverse=True)

    print("ç·åˆè©•ä¾¡ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
    for i, (method_name, total_score, scores) in enumerate(method_scores, 1):
        print(f"  {i}ä½. {method_name}: {total_score:.1f}ç‚¹")
        print(f"      é–¢é€£æ€§{scores['relevance']:.1f} + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰{scores['keywords']:.1f} + å…·ä½“æ€§{scores['specificity']:.1f} + æœ‰ç”¨æ€§{scores['helpfulness']:.1f}")

    best_method = method_scores[0][0]
    print(f"\nğŸ† æ¨å¥¨æ¤œç´¢æ–¹æ³•: {best_method}")

    # æ”¹å–„ææ¡ˆ
    print(f"\nğŸ’¡ 3-3. æ”¹å–„ææ¡ˆ")
    print("-" * 40)

    if best_scores["relevance"] < 50:
        print("âš ï¸  æ¤œç´¢é–¢é€£æ€§ãŒä½ã„ - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«é–¢é€£æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§")
        print("   æ¨å¥¨: ç·´ç¿’ãƒ»è©¦åˆäºˆå®šã®é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ")

    if best_scores["keywords"] < len(target_keywords) * 0.7:
        print("âš ï¸  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ç‡ãŒä½ã„ - ã‚ˆã‚Šé–¢é€£æ€§ã®é«˜ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ãŒå¿…è¦")
        print("   æ¨å¥¨: æ¤œç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ”¹è‰¯")

    if best_scores["specificity"] < 4:
        print("âš ï¸  LLMå›ç­”ã®å…·ä½“æ€§ãŒä¸è¶³ - ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±æä¾›ãŒå¿…è¦")
        print("   æ¨å¥¨: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ”¹è‰¯")

    print(f"\nâœ… è©•ä¾¡å®Œäº†: {datetime.now().strftime('%H:%M:%S')}")

    print("\n" + "=" * 80)
    print("ğŸ¯ ã‚¯ã‚¨ãƒªè©•ä¾¡å®Œäº† - æ¤œç´¢ç²¾åº¦ã¨LLMå›ç­”å“è³ªã®è©³ç´°åˆ†æçµæœ")
    print("=" * 80)


if __name__ == "__main__":
    evaluate_query_response()

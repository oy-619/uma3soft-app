#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æœªæ¥æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import sys
import os

sys.path.append(".")

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
from dotenv import load_dotenv
load_dotenv()

# OpenAI APIè¨­å®šã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEY environment variable is not set")


def test_final_future_filtering():
    """æœªæ¥æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ã®æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆ"""

    print("=" * 70)
    print("ğŸ† æœªæ¥æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    print()

    try:
        from langchain_chroma import Chroma
        from langchain_huggingface import HuggingFaceEmbeddings
        from langchain_openai import ChatOpenAI
        from langchain_core.prompts import ChatPromptTemplate
        from uma3_chroma_improver import Uma3ChromaDBImprover
        from uma3 import format_message_for_mobile, split_long_message

        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        embedding_model = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        vector_db = Chroma(
            persist_directory="chroma_store",
            embedding_function=embedding_model
        )
        chroma_improver = Uma3ChromaDBImprover(vector_db)

        print("âœ… ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–æˆåŠŸ")

    except Exception as e:
        print(f"âŒ åˆæœŸåŒ–å¤±æ•—: {e}")
        return

    # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_query = "ä»Šå¾Œã®äºˆå®šã‚’æ•™ãˆã¦ãã ã•ã„"
    print(f"ğŸ” ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª: '{test_query}'")
    print()

    # 1. æœªæ¥ãƒ•ã‚£ãƒ«ã‚¿ã‚ã‚Šã®æ¤œç´¢
    print("ğŸ“‹ 1. æœªæ¥ãƒ•ã‚£ãƒ«ã‚¿ã‚ã‚Šã®æ¤œç´¢")
    print("-" * 40)

    future_results = chroma_improver.schedule_aware_search(
        test_query,
        k=6,
        score_threshold=0.5,
        future_only=True  # æœªæ¥ã®ã¿
    )

    print(f"ğŸ“Š æ¤œç´¢çµæœ: {len(future_results)}ä»¶")

    if future_results:
        note_count = sum(1 for doc in future_results if "[ãƒãƒ¼ãƒˆ]" in doc.page_content)
        print(f"ğŸ“ [ãƒãƒ¼ãƒˆ]ãƒ‡ãƒ¼ã‚¿: {note_count}ä»¶ ({note_count/len(future_results)*100:.1f}%)")

        # æ­£è§£ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        target_keywords = ["æ±äº¬éƒ½å¤§ä¼š", "ç¾½æ‘ãƒ©ã‚¤ã‚ªãƒ³ã‚º", "å¤§æ£®ãƒªãƒ¼ã‚°"]
        found_targets = []
        for doc in future_results:
            for target in target_keywords:
                if target in doc.page_content:
                    found_targets.append(target)
                    break

        if found_targets:
            print(f"ğŸ¯ æ­£è§£ãƒ‡ãƒ¼ã‚¿ç™ºè¦‹: {found_targets}")

    # 2. æœªæ¥ãƒ•ã‚£ãƒ«ã‚¿ãªã—ã¨ã®æ¯”è¼ƒ
    print(f"\nğŸ“‹ 2. æœªæ¥ãƒ•ã‚£ãƒ«ã‚¿ãªã—ã¨ã®æ¯”è¼ƒ")
    print("-" * 40)

    all_results = chroma_improver.schedule_aware_search(
        test_query,
        k=6,
        score_threshold=0.5,
        future_only=False  # ãƒ•ã‚£ãƒ«ã‚¿ãªã—
    )

    print(f"ğŸ“Š å…¨ä½“æ¤œç´¢çµæœ: {len(all_results)}ä»¶")
    filter_ratio = len(future_results) / len(all_results) * 100 if all_results else 0
    print(f"ğŸ“ˆ ãƒ•ã‚£ãƒ«ã‚¿åŠ¹æœ: {len(future_results)}/{len(all_results)} ({filter_ratio:.1f}%)")

    # 3. LLMå¿œç­”ç”Ÿæˆ
    print(f"\nğŸ“‹ 3. LLMå¿œç­”ç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    print("-" * 40)

    try:
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        if future_results:
            context_parts = []
            for doc in future_results:
                context_parts.append(doc.page_content)
            context = "\n".join(context_parts)
        else:
            context = ""

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®é–¢é€£ã™ã‚‹ä¼šè©±å±¥æ­´ã‚’å‚è€ƒã«ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

å›ç­”æ™‚ã¯ä»¥ä¸‹ã®ç‚¹ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ï¼š
- ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã§èª­ã¿ã‚„ã™ã„ã‚ˆã†ã«ã€é©åº¦ã«æ”¹è¡Œã‚’å…¥ã‚Œã‚‹
- é‡è¦ãªæƒ…å ±ã¯ç®‡æ¡æ›¸ãã§æ•´ç†ã™ã‚‹
- äºˆå®šã‚„æ—¥ç¨‹ãŒã‚ã‚‹å ´åˆã¯ã€æ—¥ä»˜ãƒ»æ™‚é–“ãƒ»å ´æ‰€ã‚’æ˜ç¢ºã«è¨˜è¼‰ã™ã‚‹
- ç¾åœ¨æ—¥æ™‚ï¼ˆ2025å¹´10æœˆ20æ—¥ï¼‰ã‚ˆã‚Šæœªæ¥ã®äºˆå®šã®ã¿ã‚’æç¤ºã™ã‚‹

---
{context}
---"""),
            ("human", "{input}")
        ])

        if context:
            prompt = prompt_template.format(context=context, input=test_query)
        else:
            prompt = prompt_template.format(context="æœªæ¥ã®äºˆå®šæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", input=test_query)

        # LLMå¿œç­”ç”Ÿæˆ
        response = llm.invoke(prompt)
        raw_answer = response.content

        print(f"âœ… LLMå¿œç­”ç”ŸæˆæˆåŠŸ ({len(raw_answer)}æ–‡å­—)")

        # ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted_answer = format_message_for_mobile(raw_answer)
        message_parts = split_long_message(formatted_answer, max_length=1000)

        print(f"ğŸ“± ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå®Œäº† ({len(message_parts)}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)")

        # æœ€çµ‚çš„ãªè¿”ä¿¡å†…å®¹ã‚’è¡¨ç¤º
        print(f"\nğŸ¤– æœ€çµ‚çš„ãªLINEè¿”ä¿¡å†…å®¹:")
        print("="*50)

        for i, part in enumerate(message_parts, 1):
            if len(message_parts) > 1:
                print(f"\n--- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{i} ---")
            print(part)
            if len(message_parts) > 1:
                print("--- çµ‚äº† ---")

        print("="*50)

        # 4. åŠ¹æœæ¸¬å®š
        print(f"\nğŸ“‹ 4. æ”¹å–„åŠ¹æœæ¸¬å®š")
        print("-" * 40)

        # æœªæ¥é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å‡ºç¾ç‡
        future_keywords = ["10æœˆ", "11æœˆ", "12æœˆ", "25æ—¥", "1æ—¥", "23æ—¥", "å¤§ä¼š", "ç·´ç¿’è©¦åˆ"]
        keyword_count = sum(1 for keyword in future_keywords if keyword in raw_answer)

        print(f"ğŸ” æœªæ¥é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å«æœ‰: {keyword_count}/{len(future_keywords)} ({keyword_count/len(future_keywords)*100:.1f}%)")

        # æ—¥ä»˜ã®å…·ä½“æ€§ãƒã‚§ãƒƒã‚¯
        import re
        date_matches = re.findall(r'\d{1,2}æœˆ\d{1,2}æ—¥', raw_answer)
        print(f"ğŸ“… å…·ä½“çš„æ—¥ä»˜ã®è¨€åŠ: {len(date_matches)}ä»¶")
        if date_matches:
            print(f"   ä¾‹: {', '.join(date_matches[:3])}")

        print(f"âœ… æœªæ¥æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œ")

    except Exception as e:
        print(f"âŒ LLMå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

    print(f"\nğŸ‰ æœªæ¥æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†!")
    print("=" * 70)


if __name__ == "__main__":
    test_final_future_filtering()

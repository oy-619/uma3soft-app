"""
å®Ÿéš›ã®å¿œç­”ç”Ÿæˆãƒ†ã‚¹ãƒˆ
çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã§å®Ÿéš›ã«ã©ã®ã‚ˆã†ãªå¿œç­”ãŒç”Ÿæˆã•ã‚Œã‚‹ã‹ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
from datetime import datetime

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.join(os.path.dirname(current_dir), 'src')
sys.path.insert(0, src_dir)

def test_actual_response_generation():
    """å®Ÿéš›ã®å¿œç­”ç”Ÿæˆã‚’ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("å®Ÿéš›ã®å¿œç­”ç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸ OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("âš ï¸ å®Ÿéš›ã®å¿œç­”ç”Ÿæˆã¯ãƒ†ã‚¹ãƒˆã§ãã¾ã›ã‚“ãŒã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚")
        test_without_llm = True
    else:
        print("âœ… OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚")
        test_without_llm = False

    try:
        from integrated_conversation_system import IntegratedConversationSystem
        from langchain_openai import ChatOpenAI

        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        system = IntegratedConversationSystem(
            'Lesson25/uma3soft-app/db/chroma_store',
            'Lesson25/uma3soft-app/db/conversation_history.db'
        )

        # å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’ä½¿ç”¨
        test_user_id = "U2b1bb2a638b714727085c7317a3b54a0"

        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
        test_cases = [
            "å‰å›ã®è©±ã‚’è¦šãˆã¦ã‚‹ï¼Ÿ",
            "ã‚­ãƒ£ãƒ—ãƒ†ãƒ³ã®ä»¶ã€ã©ã†ã ã£ãŸã£ã‘ï¼Ÿ",
            "ãªãŠã¾ã•ã‚“ã®è©±ã€è¦šãˆã¦ã‚‹ï¼Ÿ",
            "ä»Šåº¦ã¯é•ã†è³ªå•ã ã‘ã©ã€ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ"
        ]

        if not test_without_llm:
            llm = ChatOpenAI(
                model="gpt-3.5-turbo",
                temperature=0.3,
                openai_api_key=os.getenv("OPENAI_API_KEY")
            )

        for i, test_message in enumerate(test_cases, 1):
            print(f"\n{i}. ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: '{test_message}'")
            print("-" * 50)

            try:
                if test_without_llm:
                    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã®ã¿ãƒ†ã‚¹ãƒˆ
                    context_prompt = system.context_generator.generate_contextual_response_prompt(
                        test_user_id, test_message, max_history_items=3
                    )

                    print("ğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
                    print(context_prompt[:500] + "..." if len(context_prompt) > 500 else context_prompt)
                    print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨ä½“ã®é•·ã•: {len(context_prompt)}æ–‡å­—")

                    # å±¥æ­´å‚ç…§ã®ç¢ºèª
                    if "ä¼šè©±å›æ•°" in context_prompt:
                        print("âœ… ä¼šè©±å›æ•°æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
                    if "æœ€è¿‘ã®ä¼šè©±å±¥æ­´" in context_prompt:
                        print("âœ… æœ€è¿‘ã®ä¼šè©±å±¥æ­´ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
                    if "ã‚­ãƒ£ãƒ—ãƒ†ãƒ³" in context_prompt:
                        print("âœ… éå»ã®ä¼šè©±å†…å®¹ï¼ˆã‚­ãƒ£ãƒ—ãƒ†ãƒ³ï¼‰ãŒå‚ç…§ã•ã‚Œã¦ã„ã¾ã™")
                    if "ãªãŠã¾" in context_prompt:
                        print("âœ… éå»ã®ä¼šè©±å†…å®¹ï¼ˆãªãŠã¾ï¼‰ãŒå‚ç…§ã•ã‚Œã¦ã„ã¾ã™")
                else:
                    # å®Ÿéš›ã«å¿œç­”ç”Ÿæˆ
                    result = system.generate_integrated_response(
                        test_user_id, test_message, llm
                    )

                    if "error" in result:
                        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result.get('error_message', 'Unknown error')}")
                    else:
                        response = result["response"]
                        context_info = result.get("context_used", {})

                        print(f"ğŸ¤– å¿œç­”: {response}")
                        print(f"ğŸ“Š ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±:")
                        print(f"   - ChromaDBæ¤œç´¢çµæœ: {context_info.get('chroma_results', 0)}ä»¶")
                        print(f"   - ä¼šè©±å±¥æ­´: {context_info.get('conversation_history', 0)}ä»¶")
                        print(f"   - é–¢é€£ä¼šè©±: {context_info.get('relevant_conversations', 0)}ä»¶")

                        # å±¥æ­´å‚ç…§ã®ç¢ºèª
                        if "ã‚­ãƒ£ãƒ—ãƒ†ãƒ³" in response or "ãªãŠã¾" in response:
                            print("âœ… éå»ã®ä¼šè©±å†…å®¹ãŒå¿œç­”ã«åæ˜ ã•ã‚Œã¦ã„ã¾ã™")
                        else:
                            print("âš ï¸ éå»ã®ä¼šè©±å†…å®¹ãŒå¿œç­”ã«ååˆ†åæ˜ ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")

                        user_profile = context_info.get('user_profile', {})
                        if user_profile and user_profile.get('conversation_count', 0) > 0:
                            print(f"âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãŒæ´»ç”¨ã•ã‚Œã¦ã„ã¾ã™ï¼ˆä¼šè©±æ•°: {user_profile['conversation_count']}ï¼‰")

            except Exception as e:
                print(f"âŒ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹{i}ã§ã‚¨ãƒ©ãƒ¼: {e}")
                import traceback
                traceback.print_exc()

    except Exception as e:
        print(f"âŒ å¿œç­”ç”Ÿæˆãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()


def test_context_quality():
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®è³ªã‚’ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ” ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå“è³ªåˆ†æ")

    try:
        from integrated_conversation_system import IntegratedConversationSystem

        system = IntegratedConversationSystem(
            'Lesson25/uma3soft-app/db/chroma_store',
            'Lesson25/uma3soft-app/db/conversation_history.db'
        )

        test_user_id = "U2b1bb2a638b714727085c7317a3b54a0"
        test_query = "å‰å›ã®è©±ã€è¦šãˆã¦ã‚‹ï¼Ÿ"

        # å€‹åˆ¥ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ãƒ†ã‚¹ãƒˆ
        print("1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«:")
        profile = system.history_manager.get_user_profile(test_user_id)
        print(f"   ä¼šè©±å›æ•°: {profile['conversation_count']}")
        print(f"   èˆˆå‘³ãƒ»é–¢å¿ƒ: {profile['interests']}")

        print("\n2. æœ€è¿‘ã®ä¼šè©±:")
        recent = system.history_manager.get_recent_conversations(test_user_id, limit=3)
        for i, (human, ai, timestamp) in enumerate(recent):
            print(f"   {i+1}. [{timestamp.strftime('%m/%d %H:%M')}]")
            print(f"      ğŸ‘¤: {human[:60]}...")
            print(f"      ğŸ¤–: {ai[:60]}...")

        print("\n3. é–¢é€£ä¼šè©±æ¤œç´¢:")
        relevant = system.history_manager.search_conversations(test_user_id, test_query, limit=3)
        for i, conv in enumerate(relevant):
            msg_type = "ğŸ‘¤" if conv["message_type"] == "human" else "ğŸ¤–"
            print(f"   {i+1}. {msg_type} {conv['content'][:60]}...")

        print("\n4. ChromaDBæ¤œç´¢:")
        chroma_results = system.chroma_improver.schedule_aware_search(test_query, k=3)
        for i, doc in enumerate(chroma_results):
            print(f"   {i+1}. {doc.page_content[:60]}...")

        print(f"\nğŸ“Š ç·åˆè©•ä¾¡:")
        print(f"   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«: {'âœ…' if profile['conversation_count'] > 0 else 'âŒ'}")
        print(f"   - æœ€è¿‘ã®ä¼šè©±: {'âœ…' if len(recent) > 0 else 'âŒ'}")
        print(f"   - é–¢é€£ä¼šè©±: {'âœ…' if len(relevant) > 0 else 'âŒ'}")
        print(f"   - ChromaDBæ¤œç´¢: {'âœ…' if len(chroma_results) > 0 else 'âŒ'}")

    except Exception as e:
        print(f"âŒ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå“è³ªåˆ†æã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    print("ğŸš€ å®Ÿéš›ã®å¿œç­”ç”Ÿæˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print(f"ğŸ“… ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    test_actual_response_generation()
    test_context_quality()

    print("\nğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")

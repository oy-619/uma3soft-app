#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import os
from dotenv import load_dotenv

sys.path.append(".")

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# OpenAI APIè¨­å®šã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEY environment variable is not set")

from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from uma3_chroma_improver import Uma3ChromaDBImprover


def test_uma3_improved():
    """æ”¹å–„ã•ã‚ŒãŸUma3ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""

    print("=" * 60)
    print("ğŸ¤– Uma3æ”¹å–„ç‰ˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    # åˆæœŸåŒ–ï¼ˆuma3.pyã¨åŒã˜è¨­å®šï¼‰
    embedding_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    vector_db = Chroma(
        persist_directory="chroma_store",
        embedding_function=embedding_model
    )

    # ChromaDBç²¾åº¦å‘ä¸Šæ©Ÿèƒ½ã®åˆæœŸåŒ–
    chroma_improver = Uma3ChromaDBImprover(vector_db)

    # OpenAI LLMåˆæœŸåŒ–
    llm = ChatOpenAI(temperature=0.7, model="gpt-3.5-turbo")

    # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_query = "ä»Šå¾Œã®äºˆå®šã‚’æ•™ãˆã¦ãã ã•ã„"
    user_id = "test_user"

    print(f"ğŸ” ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª: '{test_query}'")
    print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {user_id}")
    print()

    # ã‚¹ãƒ†ãƒƒãƒ—1: æ”¹å–„ã•ã‚ŒãŸæ¤œç´¢å®Ÿè¡Œ
    print("ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—1: æ”¹å–„æ¤œç´¢å®Ÿè¡Œ")
    print("-" * 30)

    results = chroma_improver.schedule_aware_search(
        test_query,
        k=6,
        score_threshold=0.5
    )

    print(f"âœ… æ¤œç´¢çµæœ: {len(results)}ä»¶")

    if len(results) > 0:
        note_count = sum(1 for doc in results if "[ãƒãƒ¼ãƒˆ]" in doc.page_content)
        print(f"ğŸ“ [ãƒãƒ¼ãƒˆ]ãƒ‡ãƒ¼ã‚¿: {note_count}ä»¶ ({note_count/len(results)*100:.1f}%)")

    # æ­£è§£ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    targets_found = []
    target_keywords = [
        "ç¬¬52å›æ±äº¬éƒ½å°å­¦ç”Ÿç”·å­ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ç§‹å­£å¤§ä¼š",
        "ç¾½æ‘ãƒ©ã‚¤ã‚ªãƒ³ã‚ºã•ã‚“ã¨ã®ç·´ç¿’è©¦åˆ",
        "å¤§æ£®ãƒªãƒ¼ã‚°è‹¥è‰ã‚¸ãƒ¥ãƒ‹ã‚¢æ¯"
    ]

    if len(results) > 0:
        for doc in results:
            for target in target_keywords:
                if target[:20] in doc.page_content:
                    targets_found.append(target)
                    break

    print(f"ğŸ¯ æ­£è§£ãƒ‡ãƒ¼ã‚¿ç™ºè¦‹: {len(targets_found)}/{len(target_keywords)}ä»¶")
    for target in targets_found:
        print(f"   âœ… {target}")

    # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
    print("\nğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—2: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰")
    print("-" * 30)

    if results:
        context_parts = []
        for i, doc in enumerate(results, 1):
            user = doc.metadata.get('user', 'Unknown')
            timestamp = doc.metadata.get('timestamp', 'Unknown')
            content = doc.page_content
            context_parts.append(f"{i}. [{user}] {timestamp}: {content}")

        context = "\n".join(context_parts)
        print(f"ğŸ“„ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(context)}æ–‡å­—")

        # ã‚¹ãƒ†ãƒƒãƒ—3: LLMå¿œç­”ç”Ÿæˆ
        print(f"\nğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—3: LLMå¿œç­”ç”Ÿæˆ")
        print("-" * 30)

        user_match_count = sum(1 for doc in results if doc.metadata.get('user') == user_id)
        context_quality = (user_match_count / len(results)) * 100

        if context_quality > 30:
            prompt = ChatPromptTemplate.from_messages([
                ("system", "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®éå»ã®ä¼šè©±å±¥æ­´ï¼ˆç‰¹ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éå»ã®ç™ºè¨€ï¼‰ã‚’å‚è€ƒã«ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«è‡ªç„¶ã§è¦ªã—ã¿ã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚\n---\n{context}\n---"),
                ("user", "{query}")
            ])
        else:
            prompt = ChatPromptTemplate.from_messages([
                ("system", "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®é–¢é€£ã™ã‚‹ä¼šè©±å±¥æ­´ã‚’å‚è€ƒã«ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n---\n{context}\n---"),
                ("user", "{query}")
            ])

        chain = prompt | llm

        try:
            response = chain.invoke({
                "context": context,
                "query": test_query
            })

            reply_text = response.content

            print("ğŸ¤– Uma3å›ç­”:")
            print("="*50)
            print(reply_text)
            print("="*50)

        except Exception as e:
            print(f"âŒ LLMå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")

    else:
        print("âŒ æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


if __name__ == "__main__":
    test_uma3_improved()

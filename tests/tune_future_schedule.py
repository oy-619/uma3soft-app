"""
ã€Œä»Šå¾Œã®äºˆå®šã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ã€ã‚¯ã‚¨ãƒªã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
æ­£è§£å›ç­”å†…å®¹ã¸ã®æœ€é©åŒ–
"""

import os
import sys
import time
from datetime import datetime

sys.path.append(".")

from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from uma3_chroma_improver import Uma3ChromaDBImprover


def tune_future_schedule_query():
    """ã€Œä»Šå¾Œã®äºˆå®šã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ã€ã‚¯ã‚¨ãƒªã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°"""
    print("=" * 80)
    print("ğŸ”§ ã€Œä»Šå¾Œã®äºˆå®šã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ã€ã‚¯ã‚¨ãƒªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
    print("=" * 80)

    # ã‚¯ã‚¨ãƒªã¨æ­£è§£å›ç­”ã®è¨­å®š
    target_query = "ä»Šå¾Œã®äºˆå®šã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
    correct_answers = [
        "[ãƒãƒ¼ãƒˆ] ç¬¬52å›æ±äº¬éƒ½å°å­¦ç”Ÿç”·å­ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«ç§‹å­£å¤§ä¼šã€€ã€å¤§ä¼šæ—¥ç¨‹ã€‘10æœˆ25æ—¥ï¼ˆåœŸï¼‰ï¼26æ—¥ï¼ˆæ—¥ï¼‰ï¼äºˆå‚™æ—¥ãƒ»11æœˆ1æ—¥ï¼ˆåœŸï¼‰ï¼2æ—¥ï¼ˆæ—¥ï¼‰",
        "[ãƒãƒ¼ãƒˆ] ç¾½æ‘ãƒ©ã‚¤ã‚ªãƒ³ã‚ºã•ã‚“ã¨ã®ç·´ç¿’è©¦åˆ",
        "[ãƒãƒ¼ãƒˆ] å¤§æ£®ãƒªãƒ¼ã‚°è‹¥è‰ã‚¸ãƒ¥ãƒ‹ã‚¢æ¯ï¼ˆ3å¹´ç”Ÿä»¥ä¸‹ï¼‰æ—¥æ™‚ï¼š2025/11/03(æœˆç¥)11:00ï½15:00ï¼ˆ17:00ã¾ã§åˆ©ç”¨å¯ï¼‰",
    ]

    print(f"ğŸ“‹ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¯¾è±¡ã‚¯ã‚¨ãƒª: '{target_query}'")
    print(f"ğŸ¯ æ­£è§£å›ç­”æ•°: {len(correct_answers)}ä»¶")
    print(f"â° å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # åˆæœŸåŒ–
    embedding_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    vector_db = Chroma(
        persist_directory="chroma_store", embedding_function=embedding_model
    )
    improver = Uma3ChromaDBImprover(vector_db)

    # OpenAIè¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
    if "OPENAI_API_KEY" not in os.environ:
        print("âš ï¸  OPENAI_API_KEYã®ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)

    print("\n" + "=" * 60)
    print("ğŸ“Š STEP 1: ç¾åœ¨ã®æ¤œç´¢çµæœåˆ†æ")
    print("=" * 60)

    # ç¾åœ¨ã®æ¤œç´¢çµæœã‚’ç¢ºèª
    def analyze_search_results(search_results, search_type):
        print(f"\nğŸ” {search_type}æ¤œç´¢çµæœåˆ†æ")
        print("-" * 40)

        if not search_results:
            print("âŒ æ¤œç´¢çµæœãªã—")
            return {"score": 0, "matches": [], "coverage": 0}

        # æ­£è§£å›ç­”ã¨ã®ä¸€è‡´åº¦ãƒã‚§ãƒƒã‚¯
        matches = []
        for i, doc in enumerate(search_results, 1):
            content = doc.page_content
            for j, correct in enumerate(correct_answers):
                # éƒ¨åˆ†çš„ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯
                if any(
                    keyword in content
                    for keyword in ["æ±äº¬éƒ½å°å­¦ç”Ÿ", "ç§‹å­£å¤§ä¼š", "10æœˆ25æ—¥", "10æœˆ26æ—¥"]
                ):
                    matches.append(
                        {
                            "result_idx": i,
                            "correct_idx": j,
                            "type": "ç§‹å­£å¤§ä¼š",
                            "content": content[:60],
                        }
                    )
                elif any(
                    keyword in content for keyword in ["ç¾½æ‘ãƒ©ã‚¤ã‚ªãƒ³ã‚º", "ç·´ç¿’è©¦åˆ"]
                ):
                    matches.append(
                        {
                            "result_idx": i,
                            "correct_idx": j,
                            "type": "ç·´ç¿’è©¦åˆ",
                            "content": content[:60],
                        }
                    )
                elif any(
                    keyword in content
                    for keyword in ["è‹¥è‰ã‚¸ãƒ¥ãƒ‹ã‚¢æ¯", "2025/11/03", "å¤§æ£®ãƒªãƒ¼ã‚°"]
                ):
                    matches.append(
                        {
                            "result_idx": i,
                            "correct_idx": j,
                            "type": "ã‚¸ãƒ¥ãƒ‹ã‚¢æ¯",
                            "content": content[:60],
                        }
                    )

        print(f"æ¤œç´¢çµæœæ•°: {len(search_results)}ä»¶")
        print(f"æ­£è§£ä¸€è‡´æ•°: {len(matches)}ä»¶")

        if matches:
            print("ä¸€è‡´å†…å®¹:")
            for match in matches:
                print(
                    f"  {match['result_idx']}ä½: {match['type']} - {match['content']}..."
                )

        coverage = (len(matches) / len(correct_answers)) * 100
        score = (len(matches) / len(search_results)) * 100 if search_results else 0

        print(f"æ­£è§£ã‚«ãƒãƒ¼ç‡: {coverage:.1f}% ({len(matches)}/{len(correct_answers)})")
        print(f"ç²¾åº¦ã‚¹ã‚³ã‚¢: {score:.1f}%")

        return {"score": score, "matches": matches, "coverage": coverage}

    # å„æ¤œç´¢æ–¹æ³•ã§ãƒ†ã‚¹ãƒˆ
    print("\nğŸ” 1-1. åŸºæœ¬æ¤œç´¢")
    basic_results = vector_db.similarity_search(target_query, k=10)
    basic_analysis = analyze_search_results(basic_results, "åŸºæœ¬")

    print("\nğŸ§  1-2. ã‚¹ãƒãƒ¼ãƒˆæ¤œç´¢ï¼ˆç¾åœ¨è¨­å®šï¼‰")
    smart_results = improver.smart_similarity_search(
        target_query, k=10, score_threshold=0.5, boost_recent=True
    )
    smart_analysis = analyze_search_results(smart_results, "ã‚¹ãƒãƒ¼ãƒˆ")

    # æ”¹è‰¯ç‰ˆæ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ†ã‚¹ãƒˆ
    print("\n" + "=" * 60)
    print("ğŸ”§ STEP 2: ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    # ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®ãƒ†ã‚¹ãƒˆ
    tuning_params = [
        {"threshold": 0.3, "k": 15, "desc": "é–¾å€¤ç·©å’Œãƒ»ä»¶æ•°å¢—åŠ "},
        {"threshold": 0.4, "k": 12, "desc": "ä¸­é–“è¨­å®š"},
        {"threshold": 0.6, "k": 8, "desc": "å³æ ¼è¨­å®š"},
        {"threshold": 0.5, "k": 20, "desc": "å¤§é‡å–å¾—"},
    ]

    best_params = None
    best_score = 0

    for i, params in enumerate(tuning_params, 1):
        print(f"\nğŸ§ª 2-{i}. ãƒ†ã‚¹ãƒˆ: {params['desc']}")
        print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: é–¾å€¤={params['threshold']}, ä»¶æ•°={params['k']}")

        tuned_results = improver.smart_similarity_search(
            target_query,
            k=params["k"],
            score_threshold=params["threshold"],
            boost_recent=True,
        )

        analysis = analyze_search_results(tuned_results, f"ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°{i}")

        if analysis["coverage"] > best_score:
            best_score = analysis["coverage"]
            best_params = params
            best_params["results"] = tuned_results

    print(f"\nğŸ† æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {best_params['desc']}")
    print(f"   è¨­å®š: é–¾å€¤={best_params['threshold']}, ä»¶æ•°={best_params['k']}")
    print(f"   ã‚«ãƒãƒ¼ç‡: {best_score:.1f}%")

    # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ‹¡å¼µãƒ†ã‚¹ãƒˆ
    print("\n" + "=" * 60)
    print("ğŸ¯ STEP 3: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ‹¡å¼µãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    # ã‚ˆã‚Šå…·ä½“çš„ãªã‚¯ã‚¨ãƒªã§ã®ãƒ†ã‚¹ãƒˆ
    expanded_queries = [
        "ç§‹å­£å¤§ä¼š 10æœˆ ã‚½ãƒ•ãƒˆãƒœãƒ¼ãƒ«",
        "ç·´ç¿’è©¦åˆ ç¾½æ‘ãƒ©ã‚¤ã‚ªãƒ³ã‚º",
        "è‹¥è‰ã‚¸ãƒ¥ãƒ‹ã‚¢æ¯ 11æœˆ å¤§æ£®ãƒªãƒ¼ã‚°",
        "ä»Šå¾Œã®å¤§ä¼šäºˆå®š è©¦åˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«",
        "2025å¹´ 11æœˆ äºˆå®š",
    ]

    all_expanded_results = []

    for i, expanded_query in enumerate(expanded_queries, 1):
        print(f"\nğŸ” 3-{i}. æ‹¡å¼µã‚¯ã‚¨ãƒª: '{expanded_query}'")

        expanded_results = improver.smart_similarity_search(
            expanded_query, k=best_params["k"], score_threshold=best_params["threshold"]
        )

        analysis = analyze_search_results(expanded_results, f"æ‹¡å¼µ{i}")
        all_expanded_results.extend(expanded_results)

    # é‡è¤‡é™¤å»ã—ã¦çµ±åˆ
    unique_expanded = []
    seen_content = set()
    for doc in all_expanded_results:
        content_key = doc.page_content[:50]
        if content_key not in seen_content:
            seen_content.add(content_key)
            unique_expanded.append(doc)

    print(f"\nğŸ“Š æ‹¡å¼µæ¤œç´¢çµ±åˆçµæœ")
    print("-" * 40)
    expanded_analysis = analyze_search_results(unique_expanded[:15], "çµ±åˆæ‹¡å¼µ")

    # LLMå›ç­”ç”Ÿæˆã¨ãƒ†ã‚¹ãƒˆ
    print("\n" + "=" * 60)
    print("ğŸ¤– STEP 4: LLMå›ç­”ç”Ÿæˆã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
    print("=" * 60)

    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.3,
        openai_api_key=os.getenv("OPENAI_API_KEY"),
    )

    def generate_tuned_response(search_results, prompt_type):
        if not search_results:
            return "é–¢é€£ã™ã‚‹äºˆå®šæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        context_parts = []
        for doc in search_results[:10]:
            content = doc.page_content
            # äºˆå®šé–¢é€£ã®æƒ…å ±ã‚’å„ªå…ˆ
            if any(
                keyword in content
                for keyword in ["ãƒãƒ¼ãƒˆ", "æ—¥æ™‚", "å ´æ‰€", "å¤§ä¼š", "è©¦åˆ", "äºˆå®š"]
            ):
                context_parts.append(content)

        context = "\n".join(context_parts)

        if prompt_type == "åŸºæœ¬":
            prompt_template = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®éå»ã®ä¼šè©±å±¥æ­´ã‚’å‚è€ƒã«ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n---\n{context}\n---",
                    ),
                    ("human", "{input}"),
                ]
            )
        elif prompt_type == "äºˆå®šç‰¹åŒ–":
            prompt_template = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        "ã‚ãªãŸã¯äºˆå®šç®¡ç†ã®å°‚é–€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰ä»Šå¾Œã®äºˆå®šï¼ˆå¤§ä¼šã€ç·´ç¿’è©¦åˆã€ã‚¤ãƒ™ãƒ³ãƒˆï¼‰ã‚’æ•´ç†ã—ã¦ã€æ—¥æ™‚é †ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚[ãƒãƒ¼ãƒˆ]ã§å§‹ã¾ã‚‹æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\n---\n{context}\n---",
                    ),
                    ("human", "{input}"),
                ]
            )
        elif prompt_type == "æ§‹é€ åŒ–":
            prompt_template = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        "ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰ä»Šå¾Œã®äºˆå®šã‚’æŠ½å‡ºã—ã€ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š\n1. å¤§ä¼šãƒ»è©¦åˆå\n2. æ—¥æ™‚\n3. å ´æ‰€ï¼ˆã‚ã‚Œã°ï¼‰\n\næƒ…å ±ï¼š\n---\n{context}\n---",
                    ),
                    ("human", "{input}"),
                ]
            )

        prompt = prompt_template.format(context=context, input=target_query)
        response = llm.invoke(prompt)
        return response.content

    # å„æ‰‹æ³•ã§LLMå›ç­”ã‚’ç”Ÿæˆ
    test_results = [
        {"name": "ç¾åœ¨è¨­å®š", "results": smart_results, "prompt": "åŸºæœ¬"},
        {"name": "æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿", "results": best_params["results"], "prompt": "åŸºæœ¬"},
        {"name": "æ‹¡å¼µæ¤œç´¢", "results": unique_expanded[:10], "prompt": "åŸºæœ¬"},
        {
            "name": "äºˆå®šç‰¹åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            "results": best_params["results"],
            "prompt": "äºˆå®šç‰¹åŒ–",
        },
        {
            "name": "æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            "results": best_params["results"],
            "prompt": "æ§‹é€ åŒ–",
        },
    ]

    best_response = None
    best_match_score = 0

    for i, test in enumerate(test_results, 1):
        print(f"\nğŸ¤– 4-{i}. {test['name']}ã§ã®å›ç­”ç”Ÿæˆ")
        print("-" * 40)

        response = generate_tuned_response(test["results"], test["prompt"])
        print(f"å›ç­”å†…å®¹:")
        print(response)

        # æ­£è§£å›ç­”ã¨ã®ä¸€è‡´åº¦è©•ä¾¡
        match_count = 0
        for correct in correct_answers:
            key_terms = []
            if "æ±äº¬éƒ½å°å­¦ç”Ÿ" in correct or "ç§‹å­£å¤§ä¼š" in correct:
                key_terms = ["æ±äº¬éƒ½å°å­¦ç”Ÿ", "ç§‹å­£å¤§ä¼š", "10æœˆ25æ—¥", "10æœˆ26æ—¥"]
            elif "ç¾½æ‘ãƒ©ã‚¤ã‚ªãƒ³ã‚º" in correct:
                key_terms = ["ç¾½æ‘ãƒ©ã‚¤ã‚ªãƒ³ã‚º", "ç·´ç¿’è©¦åˆ"]
            elif "è‹¥è‰ã‚¸ãƒ¥ãƒ‹ã‚¢æ¯" in correct:
                key_terms = ["è‹¥è‰ã‚¸ãƒ¥ãƒ‹ã‚¢æ¯", "å¤§æ£®ãƒªãƒ¼ã‚°", "2025/11/03", "11æœˆ"]

            if any(term in response for term in key_terms):
                match_count += 1

        match_score = (match_count / len(correct_answers)) * 100
        print(f"æ­£è§£ä¸€è‡´ç‡: {match_score:.1f}% ({match_count}/{len(correct_answers)})")

        if match_score > best_match_score:
            best_match_score = match_score
            best_response = {
                "name": test["name"],
                "response": response,
                "score": match_score,
            }

    # æœ€çµ‚ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœ
    print("\n" + "=" * 60)
    print("ğŸ¯ STEP 5: æœ€çµ‚ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœ")
    print("=" * 60)

    print(f"ğŸ† æœ€é©æ‰‹æ³•: {best_response['name']}")
    print(f"ğŸ“Š æ­£è§£ä¸€è‡´ç‡: {best_response['score']:.1f}%")
    print(f"ğŸ¯ æ¨å¥¨è¨­å®š:")
    print(f"   æ¤œç´¢é–¾å€¤: {best_params['threshold']}")
    print(f"   æ¤œç´¢ä»¶æ•°: {best_params['k']}")
    print(f"   ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: äºˆå®šç‰¹åŒ–å‹")

    print(f"\nğŸ“ æœ€é©å›ç­”ä¾‹:")
    print("-" * 40)
    print(best_response["response"])

    # ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é©ç”¨
    print("\n" + "=" * 60)
    print("âš™ï¸ STEP 6: ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®šé©ç”¨")
    print("=" * 60)

    return {
        "optimal_threshold": best_params["threshold"],
        "optimal_k": best_params["k"],
        "best_method": best_response["name"],
        "match_score": best_response["score"],
    }


if __name__ == "__main__":
    results = tune_future_schedule_query()
    print(f"\nâœ… ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†")
    print(f"æœ€é©è¨­å®š: é–¾å€¤={results['optimal_threshold']}, ä»¶æ•°={results['optimal_k']}")
    print(f"æœ€é©æ‰‹æ³•: {results['best_method']}")
    print(f"é”æˆç‡: {results['match_score']:.1f}%")

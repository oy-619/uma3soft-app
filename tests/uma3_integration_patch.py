"""
uma3.pyã«æ”¹å–„ã•ã‚ŒãŸå¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ±åˆã™ã‚‹ãŸã‚ã®å®Ÿéš›ã®ä¿®æ­£ãƒ‘ãƒƒãƒ
"""

# uma3.pyã®handle_messageé–¢æ•°å†…ã®çµ±åˆã‚·ã‚¹ãƒ†ãƒ å‘¼ã³å‡ºã—éƒ¨åˆ†ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼š

IMPROVED_INTEGRATION_PATCH = '''
                # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã§å¿œç­”ç”Ÿæˆï¼ˆæ”¹å–„ç‰ˆï¼‰
                print(f"[ENHANCED] Trying improved response system first...")

                # 1. æ”¹å–„ã•ã‚ŒãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’è©¦è¡Œ
                enhanced_response = None
                try:
                    # ImprovedResponseGeneratorã‚’åˆæœŸåŒ–ï¼ˆå¿…è¦æ™‚ã®ã¿ï¼‰
                    if not hasattr(handle_message, 'improved_generator'):
                        from tests.improved_response_system import ImprovedResponseGenerator
                        db_path = os.path.join(os.path.dirname(__file__), '..', 'db', 'conversation_history.db')
                        handle_message.improved_generator = ImprovedResponseGenerator(db_path)
                        print("[ENHANCED] Improved response generator initialized")

                    # æ”¹å–„ã•ã‚ŒãŸå¿œç­”ç”Ÿæˆ
                    improved_result = handle_message.improved_generator.generate_improved_response(user_id, text)

                    # é«˜å“è³ªãªå¿œç­”ãŒç”Ÿæˆã•ã‚ŒãŸå ´åˆã¯ä½¿ç”¨
                    if improved_result.get('quality_score', 0) >= 3.0:
                        enhanced_response = improved_result['response']
                        print(f"[ENHANCED] âœ… High quality response (score: {improved_result['quality_score']:.1f})")

                        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ä¼šè©±å±¥æ­´ã«ä¿å­˜
                        try:
                            integrated_conversation_system.history_manager.save_conversation(
                                user_id, text, enhanced_response,
                                metadata={
                                    "source": "enhanced_template",
                                    "quality_score": improved_result['quality_score'],
                                    "template_type": improved_result.get('template_type', 'unknown')
                                }
                            )
                            print(f"[ENHANCED] âœ… Saved enhanced conversation to history")
                        except Exception as save_error:
                            print(f"[WARNING] âŒ Failed to save enhanced conversation: {save_error}")

                    else:
                        print(f"[ENHANCED] âš ï¸ Low quality response, trying integrated system (score: {improved_result['quality_score']:.1f})")

                except Exception as e:
                    print(f"[WARNING] Enhanced response generation failed: {e}")

                # 2. æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ ã§é«˜å“è³ªãªå¿œç­”ãŒå¾—ã‚‰ã‚ŒãŸå ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
                if enhanced_response:
                    ai_msg = {"answer": enhanced_response}
                    print(f"[ENHANCED] Using enhanced template response")

                else:
                    # 3. æ—¢å­˜ã®çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    response_result = integrated_conversation_system.generate_integrated_response(
                        user_id, text, llm
                    )

                    if "error" in response_result:
                        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                        print(f"[ERROR] Integrated system error: {response_result.get('error_message', 'Unknown error')}")

                        # ChromaDBæ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        results = chroma_improver.schedule_aware_search(
                            text, k=6, score_threshold=0.5
                        )

                        if results:
                            context = "\\n".join([doc.page_content for doc in results])

                            prompt_template = ChatPromptTemplate.from_messages([
                                (
                                    "system",
                                    """ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®é–¢é€£æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ã€
                                    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«è‡ªç„¶ã§è¦ªã—ã¿ã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚
                                    å›ç­”æ™‚ã¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã§èª­ã¿ã‚„ã™ã„ã‚ˆã†ã«ã€é©åº¦ã«æ”¹è¡Œã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚

                                    ---
                                    {context}
                                    ---""",
                                ),
                                ("human", "{input}"),
                            ])

                            formatted_prompt = prompt_template.format_messages(
                                context=context, input=text
                            )
                            response = llm.invoke(formatted_prompt)
                            ai_msg = {"answer": response.content}
                        else:
                            ai_msg = {"answer": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"}
                    else:
                        # æ­£å¸¸å¿œç­”ã®å ´åˆ
                        ai_msg = {"answer": response_result["response"]}

                        # å¿œç­”æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
                        context_info = response_result.get("context_used", {})
                        print(f"[INTEGRATED] Response generated successfully")
                        print(f"[INTEGRATED] ChromaDB results: {context_info.get('chroma_results', 0)}")
                        print(f"[INTEGRATED] Conversation history: {context_info.get('conversation_history', 0)}")
                        print(f"[INTEGRATED] Response type: {response_result.get('response_type', 'unknown')}")

                        # ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
                        user_profile = context_info.get('user_profile', {})
                        if user_profile:
                            print(f"[PROFILE] User conversation count: {user_profile.get('conversation_count', 0)}")
                            if user_profile.get('interests'):
                                print(f"[PROFILE] User interests: {user_profile['interests'][:3]}")

                        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã§ç”Ÿæˆã—ãŸä¼šè©±ã‚’å±¥æ­´ã«ä¿å­˜ï¼ˆæ”¹å–„ã‚·ã‚¹ãƒ†ãƒ ã§ãªã„å ´åˆã®ã¿ï¼‰
                        if not enhanced_response:
                            try:
                                integrated_conversation_system.history_manager.save_conversation(
                                    user_id, text, ai_msg["answer"],
                                    metadata={"source": "line_mention", "response_type": response_result.get('response_type', 'integrated')}
                                )
                                print(f"[HISTORY] âœ… Saved conversation to history (user: {user_id[:10]}...)")
                            except Exception as save_error:
                                print(f"[WARNING] âŒ Failed to save conversation to history: {save_error}")
                                traceback.print_exc()
'''

def apply_enhanced_integration():
    """uma3.pyã«æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ±åˆã™ã‚‹æ‰‹é †ã‚’è¡¨ç¤º"""

    print("ğŸ”§ uma3.py æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ çµ±åˆæ‰‹é †")
    print("=" * 60)

    print("ğŸ“‹ ä¿®æ­£ãŒå¿…è¦ãªç®‡æ‰€:")
    print("1. handle_messageé–¢æ•°å†…ã®çµ±åˆã‚·ã‚¹ãƒ†ãƒ å‘¼ã³å‡ºã—éƒ¨åˆ†")
    print("   (ç´„468è¡Œç›®ï½540è¡Œç›®ä»˜è¿‘)")
    print()

    print("ğŸ” ç½®ãæ›ãˆå¯¾è±¡ã‚³ãƒ¼ãƒ‰:")
    print("   # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã§å¿œç­”ç”Ÿæˆ")
    print("   response_result = integrated_conversation_system.generate_integrated_response(")
    print("       user_id, text, llm")
    print("   )")
    print()

    print("ğŸ†• æ–°ã—ã„ã‚³ãƒ¼ãƒ‰:")
    print("   ä¸Šè¨˜ã®IMPROVED_INTEGRATION_PATCHã®å†…å®¹ã§ç½®ãæ›ãˆ")
    print()

    print("âœ… æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„:")
    print("   - é«˜å“è³ªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¿œç­”ã®å„ªå…ˆä½¿ç”¨")
    print("   - è‡ªç„¶ãªæ—¥æœ¬èªå¿œç­”")
    print("   - ãƒ¦ãƒ¼ã‚¶ãƒ¼åã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚º")
    print("   - å“è³ªã‚¹ã‚³ã‚¢3.0ä»¥ä¸Šã®å¿œç­”å„ªå…ˆ")
    print("   - æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¸ã®å®‰å…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")

    return IMPROVED_INTEGRATION_PATCH

def main():
    """çµ±åˆãƒ‘ãƒƒãƒã®è¡¨ç¤º"""
    patch_code = apply_enhanced_integration()

    print("\n" + "="*80)
    print("ğŸ“„ INTEGRATION PATCH CODE:")
    print("="*80)
    print(patch_code)
    print("="*80)

if __name__ == "__main__":
    main()
